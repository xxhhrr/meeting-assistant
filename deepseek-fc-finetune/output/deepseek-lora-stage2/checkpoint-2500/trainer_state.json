{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 2500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0,
      "grad_norm": 1.296875,
      "learning_rate": 4.993333333333334e-05,
      "loss": 3.1243,
      "step": 5
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.2109375,
      "learning_rate": 4.986666666666667e-05,
      "loss": 2.9552,
      "step": 10
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.2421875,
      "learning_rate": 4.9800000000000004e-05,
      "loss": 2.4971,
      "step": 15
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.109375,
      "learning_rate": 4.973333333333334e-05,
      "loss": 2.1835,
      "step": 20
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.046875,
      "learning_rate": 4.966666666666667e-05,
      "loss": 1.7747,
      "step": 25
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.828125,
      "learning_rate": 4.96e-05,
      "loss": 1.4143,
      "step": 30
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.828125,
      "learning_rate": 4.9533333333333336e-05,
      "loss": 1.1781,
      "step": 35
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.5625,
      "learning_rate": 4.9466666666666665e-05,
      "loss": 0.9502,
      "step": 40
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.0390625,
      "learning_rate": 4.94e-05,
      "loss": 0.8263,
      "step": 45
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.4765625,
      "learning_rate": 4.933333333333334e-05,
      "loss": 0.7956,
      "step": 50
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.88671875,
      "learning_rate": 4.926666666666667e-05,
      "loss": 0.687,
      "step": 55
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.65625,
      "learning_rate": 4.92e-05,
      "loss": 0.7025,
      "step": 60
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.359375,
      "learning_rate": 4.913333333333334e-05,
      "loss": 0.6375,
      "step": 65
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.4609375,
      "learning_rate": 4.906666666666667e-05,
      "loss": 0.62,
      "step": 70
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.125,
      "learning_rate": 4.9e-05,
      "loss": 0.6082,
      "step": 75
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.0859375,
      "learning_rate": 4.8933333333333335e-05,
      "loss": 0.6,
      "step": 80
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.8984375,
      "learning_rate": 4.886666666666667e-05,
      "loss": 0.6134,
      "step": 85
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.9609375,
      "learning_rate": 4.88e-05,
      "loss": 0.5941,
      "step": 90
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.80078125,
      "learning_rate": 4.8733333333333337e-05,
      "loss": 0.5595,
      "step": 95
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.0,
      "learning_rate": 4.866666666666667e-05,
      "loss": 0.5547,
      "step": 100
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.96875,
      "learning_rate": 4.86e-05,
      "loss": 0.547,
      "step": 105
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.96484375,
      "learning_rate": 4.853333333333334e-05,
      "loss": 0.558,
      "step": 110
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.0078125,
      "learning_rate": 4.8466666666666675e-05,
      "loss": 0.5383,
      "step": 115
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.5078125,
      "learning_rate": 4.8400000000000004e-05,
      "loss": 0.526,
      "step": 120
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.140625,
      "learning_rate": 4.8333333333333334e-05,
      "loss": 0.5107,
      "step": 125
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.84765625,
      "learning_rate": 4.826666666666667e-05,
      "loss": 0.5408,
      "step": 130
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.1171875,
      "learning_rate": 4.82e-05,
      "loss": 0.4986,
      "step": 135
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.91015625,
      "learning_rate": 4.8133333333333336e-05,
      "loss": 0.4926,
      "step": 140
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.015625,
      "learning_rate": 4.806666666666667e-05,
      "loss": 0.5046,
      "step": 145
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.6015625,
      "learning_rate": 4.8e-05,
      "loss": 0.4923,
      "step": 150
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.92578125,
      "learning_rate": 4.793333333333334e-05,
      "loss": 0.5066,
      "step": 155
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.078125,
      "learning_rate": 4.7866666666666674e-05,
      "loss": 0.4037,
      "step": 160
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.375,
      "learning_rate": 4.78e-05,
      "loss": 0.4724,
      "step": 165
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.0234375,
      "learning_rate": 4.773333333333333e-05,
      "loss": 0.4663,
      "step": 170
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.7578125,
      "learning_rate": 4.766666666666667e-05,
      "loss": 0.4671,
      "step": 175
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.78125,
      "learning_rate": 4.76e-05,
      "loss": 0.496,
      "step": 180
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.953125,
      "learning_rate": 4.7533333333333334e-05,
      "loss": 0.4474,
      "step": 185
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.0,
      "learning_rate": 4.746666666666667e-05,
      "loss": 0.461,
      "step": 190
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.8671875,
      "learning_rate": 4.74e-05,
      "loss": 0.5061,
      "step": 195
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.2109375,
      "learning_rate": 4.7333333333333336e-05,
      "loss": 0.4297,
      "step": 200
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.73046875,
      "learning_rate": 4.726666666666667e-05,
      "loss": 0.4767,
      "step": 205
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.8046875,
      "learning_rate": 4.72e-05,
      "loss": 0.4857,
      "step": 210
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.640625,
      "learning_rate": 4.713333333333333e-05,
      "loss": 0.5131,
      "step": 215
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.984375,
      "learning_rate": 4.706666666666667e-05,
      "loss": 0.4899,
      "step": 220
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.796875,
      "learning_rate": 4.7e-05,
      "loss": 0.4179,
      "step": 225
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.69140625,
      "learning_rate": 4.6933333333333333e-05,
      "loss": 0.395,
      "step": 230
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.28125,
      "learning_rate": 4.686666666666667e-05,
      "loss": 0.4415,
      "step": 235
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.6328125,
      "learning_rate": 4.6800000000000006e-05,
      "loss": 0.4984,
      "step": 240
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.1953125,
      "learning_rate": 4.6733333333333335e-05,
      "loss": 0.4358,
      "step": 245
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.97265625,
      "learning_rate": 4.666666666666667e-05,
      "loss": 0.3998,
      "step": 250
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.58984375,
      "learning_rate": 4.660000000000001e-05,
      "loss": 0.3777,
      "step": 255
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.75,
      "learning_rate": 4.653333333333334e-05,
      "loss": 0.4741,
      "step": 260
    },
    {
      "epoch": 0.21,
      "grad_norm": 1.1953125,
      "learning_rate": 4.646666666666667e-05,
      "loss": 0.4387,
      "step": 265
    },
    {
      "epoch": 0.22,
      "grad_norm": 1.1171875,
      "learning_rate": 4.64e-05,
      "loss": 0.4114,
      "step": 270
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.7421875,
      "learning_rate": 4.633333333333333e-05,
      "loss": 0.4181,
      "step": 275
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.765625,
      "learning_rate": 4.626666666666667e-05,
      "loss": 0.497,
      "step": 280
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.9140625,
      "learning_rate": 4.6200000000000005e-05,
      "loss": 0.4533,
      "step": 285
    },
    {
      "epoch": 0.23,
      "grad_norm": 1.15625,
      "learning_rate": 4.6133333333333334e-05,
      "loss": 0.4247,
      "step": 290
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.765625,
      "learning_rate": 4.606666666666667e-05,
      "loss": 0.4975,
      "step": 295
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.9921875,
      "learning_rate": 4.600000000000001e-05,
      "loss": 0.4668,
      "step": 300
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.74609375,
      "learning_rate": 4.5933333333333336e-05,
      "loss": 0.4149,
      "step": 305
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.6171875,
      "learning_rate": 4.5866666666666666e-05,
      "loss": 0.4289,
      "step": 310
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.625,
      "learning_rate": 4.58e-05,
      "loss": 0.3933,
      "step": 315
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.79296875,
      "learning_rate": 4.573333333333333e-05,
      "loss": 0.4191,
      "step": 320
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.94140625,
      "learning_rate": 4.566666666666667e-05,
      "loss": 0.4909,
      "step": 325
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.5625,
      "learning_rate": 4.5600000000000004e-05,
      "loss": 0.4312,
      "step": 330
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.5390625,
      "learning_rate": 4.553333333333333e-05,
      "loss": 0.4889,
      "step": 335
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.671875,
      "learning_rate": 4.546666666666667e-05,
      "loss": 0.4362,
      "step": 340
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.5078125,
      "learning_rate": 4.5400000000000006e-05,
      "loss": 0.4703,
      "step": 345
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.59375,
      "learning_rate": 4.5333333333333335e-05,
      "loss": 0.4252,
      "step": 350
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.8046875,
      "learning_rate": 4.526666666666667e-05,
      "loss": 0.3799,
      "step": 355
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.79296875,
      "learning_rate": 4.52e-05,
      "loss": 0.4168,
      "step": 360
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.64453125,
      "learning_rate": 4.513333333333333e-05,
      "loss": 0.4178,
      "step": 365
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.7890625,
      "learning_rate": 4.5066666666666667e-05,
      "loss": 0.4141,
      "step": 370
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.84765625,
      "learning_rate": 4.5e-05,
      "loss": 0.4114,
      "step": 375
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.66015625,
      "learning_rate": 4.493333333333333e-05,
      "loss": 0.4852,
      "step": 380
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.62890625,
      "learning_rate": 4.486666666666667e-05,
      "loss": 0.4376,
      "step": 385
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.83984375,
      "learning_rate": 4.4800000000000005e-05,
      "loss": 0.4359,
      "step": 390
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.75,
      "learning_rate": 4.473333333333334e-05,
      "loss": 0.4271,
      "step": 395
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.63671875,
      "learning_rate": 4.466666666666667e-05,
      "loss": 0.3678,
      "step": 400
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.6015625,
      "learning_rate": 4.46e-05,
      "loss": 0.4635,
      "step": 405
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.6171875,
      "learning_rate": 4.4533333333333336e-05,
      "loss": 0.4084,
      "step": 410
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.6796875,
      "learning_rate": 4.4466666666666666e-05,
      "loss": 0.3894,
      "step": 415
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.486328125,
      "learning_rate": 4.44e-05,
      "loss": 0.3738,
      "step": 420
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.734375,
      "learning_rate": 4.433333333333334e-05,
      "loss": 0.4118,
      "step": 425
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.75,
      "learning_rate": 4.426666666666667e-05,
      "loss": 0.4458,
      "step": 430
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.5625,
      "learning_rate": 4.4200000000000004e-05,
      "loss": 0.4907,
      "step": 435
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.67578125,
      "learning_rate": 4.413333333333334e-05,
      "loss": 0.3656,
      "step": 440
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.60546875,
      "learning_rate": 4.406666666666667e-05,
      "loss": 0.4188,
      "step": 445
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.7109375,
      "learning_rate": 4.4000000000000006e-05,
      "loss": 0.4579,
      "step": 450
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.53515625,
      "learning_rate": 4.3933333333333335e-05,
      "loss": 0.4405,
      "step": 455
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.078125,
      "learning_rate": 4.3866666666666665e-05,
      "loss": 0.3888,
      "step": 460
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.640625,
      "learning_rate": 4.38e-05,
      "loss": 0.4771,
      "step": 465
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.62890625,
      "learning_rate": 4.373333333333334e-05,
      "loss": 0.4341,
      "step": 470
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.55078125,
      "learning_rate": 4.3666666666666666e-05,
      "loss": 0.4233,
      "step": 475
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.64453125,
      "learning_rate": 4.36e-05,
      "loss": 0.372,
      "step": 480
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.494140625,
      "learning_rate": 4.353333333333334e-05,
      "loss": 0.4438,
      "step": 485
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.76953125,
      "learning_rate": 4.346666666666667e-05,
      "loss": 0.4352,
      "step": 490
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.73046875,
      "learning_rate": 4.3400000000000005e-05,
      "loss": 0.3877,
      "step": 495
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.59765625,
      "learning_rate": 4.3333333333333334e-05,
      "loss": 0.3602,
      "step": 500
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.5859375,
      "learning_rate": 4.3266666666666664e-05,
      "loss": 0.397,
      "step": 505
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.734375,
      "learning_rate": 4.32e-05,
      "loss": 0.4229,
      "step": 510
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.6640625,
      "learning_rate": 4.3133333333333336e-05,
      "loss": 0.424,
      "step": 515
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.5390625,
      "learning_rate": 4.3066666666666665e-05,
      "loss": 0.3886,
      "step": 520
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.796875,
      "learning_rate": 4.3e-05,
      "loss": 0.3997,
      "step": 525
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.53125,
      "learning_rate": 4.293333333333334e-05,
      "loss": 0.3487,
      "step": 530
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.5,
      "learning_rate": 4.286666666666667e-05,
      "loss": 0.382,
      "step": 535
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.66796875,
      "learning_rate": 4.2800000000000004e-05,
      "loss": 0.4081,
      "step": 540
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.68359375,
      "learning_rate": 4.273333333333333e-05,
      "loss": 0.4053,
      "step": 545
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.482421875,
      "learning_rate": 4.266666666666667e-05,
      "loss": 0.4213,
      "step": 550
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.62890625,
      "learning_rate": 4.26e-05,
      "loss": 0.3769,
      "step": 555
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.609375,
      "learning_rate": 4.2533333333333335e-05,
      "loss": 0.4493,
      "step": 560
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.61328125,
      "learning_rate": 4.246666666666667e-05,
      "loss": 0.4213,
      "step": 565
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.55859375,
      "learning_rate": 4.24e-05,
      "loss": 0.3714,
      "step": 570
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.6796875,
      "learning_rate": 4.233333333333334e-05,
      "loss": 0.4597,
      "step": 575
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.5234375,
      "learning_rate": 4.226666666666667e-05,
      "loss": 0.3968,
      "step": 580
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.55078125,
      "learning_rate": 4.22e-05,
      "loss": 0.3647,
      "step": 585
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.5078125,
      "learning_rate": 4.213333333333334e-05,
      "loss": 0.3836,
      "step": 590
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.53515625,
      "learning_rate": 4.206666666666667e-05,
      "loss": 0.4025,
      "step": 595
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.5390625,
      "learning_rate": 4.2e-05,
      "loss": 0.3641,
      "step": 600
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.6171875,
      "learning_rate": 4.1933333333333334e-05,
      "loss": 0.3841,
      "step": 605
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.6171875,
      "learning_rate": 4.186666666666667e-05,
      "loss": 0.4576,
      "step": 610
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.60546875,
      "learning_rate": 4.18e-05,
      "loss": 0.3973,
      "step": 615
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.578125,
      "learning_rate": 4.1733333333333336e-05,
      "loss": 0.3868,
      "step": 620
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.66015625,
      "learning_rate": 4.166666666666667e-05,
      "loss": 0.4058,
      "step": 625
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.609375,
      "learning_rate": 4.16e-05,
      "loss": 0.4172,
      "step": 630
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.63671875,
      "learning_rate": 4.153333333333334e-05,
      "loss": 0.4086,
      "step": 635
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.515625,
      "learning_rate": 4.146666666666667e-05,
      "loss": 0.4419,
      "step": 640
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.58203125,
      "learning_rate": 4.14e-05,
      "loss": 0.3813,
      "step": 645
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.72265625,
      "learning_rate": 4.133333333333333e-05,
      "loss": 0.4212,
      "step": 650
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.1328125,
      "learning_rate": 4.126666666666667e-05,
      "loss": 0.4075,
      "step": 655
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.67578125,
      "learning_rate": 4.12e-05,
      "loss": 0.416,
      "step": 660
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.54296875,
      "learning_rate": 4.1133333333333335e-05,
      "loss": 0.4164,
      "step": 665
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.5078125,
      "learning_rate": 4.106666666666667e-05,
      "loss": 0.3611,
      "step": 670
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.59765625,
      "learning_rate": 4.1e-05,
      "loss": 0.3738,
      "step": 675
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.51953125,
      "learning_rate": 4.093333333333334e-05,
      "loss": 0.4674,
      "step": 680
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.66796875,
      "learning_rate": 4.086666666666667e-05,
      "loss": 0.3711,
      "step": 685
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.5859375,
      "learning_rate": 4.08e-05,
      "loss": 0.4038,
      "step": 690
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.6171875,
      "learning_rate": 4.073333333333333e-05,
      "loss": 0.4243,
      "step": 695
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.65625,
      "learning_rate": 4.066666666666667e-05,
      "loss": 0.4495,
      "step": 700
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.46875,
      "learning_rate": 4.0600000000000004e-05,
      "loss": 0.4513,
      "step": 705
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.54296875,
      "learning_rate": 4.0533333333333334e-05,
      "loss": 0.4274,
      "step": 710
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.54296875,
      "learning_rate": 4.046666666666667e-05,
      "loss": 0.3725,
      "step": 715
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.51953125,
      "learning_rate": 4.0400000000000006e-05,
      "loss": 0.4682,
      "step": 720
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.75,
      "learning_rate": 4.0333333333333336e-05,
      "loss": 0.3894,
      "step": 725
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.46484375,
      "learning_rate": 4.026666666666667e-05,
      "loss": 0.4016,
      "step": 730
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.546875,
      "learning_rate": 4.02e-05,
      "loss": 0.4009,
      "step": 735
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.54296875,
      "learning_rate": 4.013333333333333e-05,
      "loss": 0.3614,
      "step": 740
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.54296875,
      "learning_rate": 4.006666666666667e-05,
      "loss": 0.4344,
      "step": 745
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.5390625,
      "learning_rate": 4e-05,
      "loss": 0.3973,
      "step": 750
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.48828125,
      "learning_rate": 3.993333333333333e-05,
      "loss": 0.4071,
      "step": 755
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.51171875,
      "learning_rate": 3.986666666666667e-05,
      "loss": 0.3759,
      "step": 760
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.5234375,
      "learning_rate": 3.9800000000000005e-05,
      "loss": 0.407,
      "step": 765
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.61328125,
      "learning_rate": 3.9733333333333335e-05,
      "loss": 0.4242,
      "step": 770
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.640625,
      "learning_rate": 3.966666666666667e-05,
      "loss": 0.42,
      "step": 775
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.61328125,
      "learning_rate": 3.960000000000001e-05,
      "loss": 0.4128,
      "step": 780
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.46875,
      "learning_rate": 3.9533333333333337e-05,
      "loss": 0.3931,
      "step": 785
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.62890625,
      "learning_rate": 3.9466666666666666e-05,
      "loss": 0.4225,
      "step": 790
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.79296875,
      "learning_rate": 3.94e-05,
      "loss": 0.4115,
      "step": 795
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.52734375,
      "learning_rate": 3.933333333333333e-05,
      "loss": 0.4237,
      "step": 800
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.9453125,
      "learning_rate": 3.926666666666667e-05,
      "loss": 0.385,
      "step": 805
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.52734375,
      "learning_rate": 3.9200000000000004e-05,
      "loss": 0.3476,
      "step": 810
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.65234375,
      "learning_rate": 3.9133333333333334e-05,
      "loss": 0.3797,
      "step": 815
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.60546875,
      "learning_rate": 3.906666666666667e-05,
      "loss": 0.3423,
      "step": 820
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.53515625,
      "learning_rate": 3.9000000000000006e-05,
      "loss": 0.4131,
      "step": 825
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.70703125,
      "learning_rate": 3.8933333333333336e-05,
      "loss": 0.3941,
      "step": 830
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.49609375,
      "learning_rate": 3.8866666666666665e-05,
      "loss": 0.4403,
      "step": 835
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.6484375,
      "learning_rate": 3.88e-05,
      "loss": 0.3942,
      "step": 840
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.53515625,
      "learning_rate": 3.873333333333333e-05,
      "loss": 0.3629,
      "step": 845
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.4921875,
      "learning_rate": 3.866666666666667e-05,
      "loss": 0.3639,
      "step": 850
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.447265625,
      "learning_rate": 3.86e-05,
      "loss": 0.4552,
      "step": 855
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.5859375,
      "learning_rate": 3.853333333333334e-05,
      "loss": 0.3938,
      "step": 860
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.48046875,
      "learning_rate": 3.846666666666667e-05,
      "loss": 0.3932,
      "step": 865
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.52734375,
      "learning_rate": 3.8400000000000005e-05,
      "loss": 0.3803,
      "step": 870
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.6484375,
      "learning_rate": 3.8333333333333334e-05,
      "loss": 0.3937,
      "step": 875
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.4609375,
      "learning_rate": 3.8266666666666664e-05,
      "loss": 0.3954,
      "step": 880
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.6640625,
      "learning_rate": 3.82e-05,
      "loss": 0.437,
      "step": 885
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.62890625,
      "learning_rate": 3.8133333333333336e-05,
      "loss": 0.3744,
      "step": 890
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.80859375,
      "learning_rate": 3.8066666666666666e-05,
      "loss": 0.4458,
      "step": 895
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.5625,
      "learning_rate": 3.8e-05,
      "loss": 0.4323,
      "step": 900
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.482421875,
      "learning_rate": 3.793333333333334e-05,
      "loss": 0.4156,
      "step": 905
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.439453125,
      "learning_rate": 3.786666666666667e-05,
      "loss": 0.3827,
      "step": 910
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.470703125,
      "learning_rate": 3.7800000000000004e-05,
      "loss": 0.4325,
      "step": 915
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.8125,
      "learning_rate": 3.773333333333334e-05,
      "loss": 0.4014,
      "step": 920
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.984375,
      "learning_rate": 3.766666666666667e-05,
      "loss": 0.3786,
      "step": 925
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.5703125,
      "learning_rate": 3.76e-05,
      "loss": 0.364,
      "step": 930
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.443359375,
      "learning_rate": 3.7533333333333335e-05,
      "loss": 0.3804,
      "step": 935
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.4921875,
      "learning_rate": 3.7466666666666665e-05,
      "loss": 0.3588,
      "step": 940
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.46875,
      "learning_rate": 3.74e-05,
      "loss": 0.3478,
      "step": 945
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.482421875,
      "learning_rate": 3.733333333333334e-05,
      "loss": 0.3856,
      "step": 950
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.546875,
      "learning_rate": 3.726666666666667e-05,
      "loss": 0.4357,
      "step": 955
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.4921875,
      "learning_rate": 3.72e-05,
      "loss": 0.4192,
      "step": 960
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.400390625,
      "learning_rate": 3.713333333333334e-05,
      "loss": 0.3934,
      "step": 965
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.39453125,
      "learning_rate": 3.706666666666667e-05,
      "loss": 0.399,
      "step": 970
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.5625,
      "learning_rate": 3.7e-05,
      "loss": 0.4146,
      "step": 975
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.578125,
      "learning_rate": 3.6933333333333334e-05,
      "loss": 0.3707,
      "step": 980
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.5859375,
      "learning_rate": 3.6866666666666664e-05,
      "loss": 0.3538,
      "step": 985
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.5390625,
      "learning_rate": 3.68e-05,
      "loss": 0.4547,
      "step": 990
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.55859375,
      "learning_rate": 3.6733333333333336e-05,
      "loss": 0.423,
      "step": 995
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.41796875,
      "learning_rate": 3.6666666666666666e-05,
      "loss": 0.4266,
      "step": 1000
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.55078125,
      "learning_rate": 3.66e-05,
      "loss": 0.402,
      "step": 1005
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.486328125,
      "learning_rate": 3.653333333333334e-05,
      "loss": 0.4044,
      "step": 1010
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.6484375,
      "learning_rate": 3.646666666666667e-05,
      "loss": 0.4032,
      "step": 1015
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.50390625,
      "learning_rate": 3.6400000000000004e-05,
      "loss": 0.3527,
      "step": 1020
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.578125,
      "learning_rate": 3.633333333333333e-05,
      "loss": 0.4302,
      "step": 1025
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.5703125,
      "learning_rate": 3.626666666666667e-05,
      "loss": 0.371,
      "step": 1030
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.53515625,
      "learning_rate": 3.62e-05,
      "loss": 0.3838,
      "step": 1035
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.58984375,
      "learning_rate": 3.6133333333333335e-05,
      "loss": 0.4493,
      "step": 1040
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.5078125,
      "learning_rate": 3.606666666666667e-05,
      "loss": 0.4051,
      "step": 1045
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.51171875,
      "learning_rate": 3.6e-05,
      "loss": 0.3757,
      "step": 1050
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.494140625,
      "learning_rate": 3.593333333333334e-05,
      "loss": 0.3247,
      "step": 1055
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.3984375,
      "learning_rate": 3.586666666666667e-05,
      "loss": 0.3801,
      "step": 1060
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.478515625,
      "learning_rate": 3.58e-05,
      "loss": 0.4087,
      "step": 1065
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.515625,
      "learning_rate": 3.573333333333333e-05,
      "loss": 0.3534,
      "step": 1070
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.455078125,
      "learning_rate": 3.566666666666667e-05,
      "loss": 0.3805,
      "step": 1075
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.5390625,
      "learning_rate": 3.56e-05,
      "loss": 0.3896,
      "step": 1080
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.48828125,
      "learning_rate": 3.5533333333333334e-05,
      "loss": 0.4028,
      "step": 1085
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.455078125,
      "learning_rate": 3.546666666666667e-05,
      "loss": 0.3851,
      "step": 1090
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.4375,
      "learning_rate": 3.54e-05,
      "loss": 0.4116,
      "step": 1095
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.53515625,
      "learning_rate": 3.5333333333333336e-05,
      "loss": 0.36,
      "step": 1100
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.54296875,
      "learning_rate": 3.526666666666667e-05,
      "loss": 0.3997,
      "step": 1105
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.39453125,
      "learning_rate": 3.52e-05,
      "loss": 0.3361,
      "step": 1110
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.625,
      "learning_rate": 3.513333333333334e-05,
      "loss": 0.3488,
      "step": 1115
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.482421875,
      "learning_rate": 3.506666666666667e-05,
      "loss": 0.4046,
      "step": 1120
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.494140625,
      "learning_rate": 3.5e-05,
      "loss": 0.3726,
      "step": 1125
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.48046875,
      "learning_rate": 3.493333333333333e-05,
      "loss": 0.3833,
      "step": 1130
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.53515625,
      "learning_rate": 3.486666666666667e-05,
      "loss": 0.3603,
      "step": 1135
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.53125,
      "learning_rate": 3.48e-05,
      "loss": 0.394,
      "step": 1140
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.59765625,
      "learning_rate": 3.4733333333333335e-05,
      "loss": 0.3833,
      "step": 1145
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.44140625,
      "learning_rate": 3.466666666666667e-05,
      "loss": 0.3807,
      "step": 1150
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.72265625,
      "learning_rate": 3.46e-05,
      "loss": 0.3701,
      "step": 1155
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.490234375,
      "learning_rate": 3.453333333333334e-05,
      "loss": 0.4394,
      "step": 1160
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.58203125,
      "learning_rate": 3.4466666666666666e-05,
      "loss": 0.4344,
      "step": 1165
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.421875,
      "learning_rate": 3.4399999999999996e-05,
      "loss": 0.4321,
      "step": 1170
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.5234375,
      "learning_rate": 3.433333333333333e-05,
      "loss": 0.3453,
      "step": 1175
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.478515625,
      "learning_rate": 3.426666666666667e-05,
      "loss": 0.3666,
      "step": 1180
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.51171875,
      "learning_rate": 3.4200000000000005e-05,
      "loss": 0.3791,
      "step": 1185
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.494140625,
      "learning_rate": 3.4133333333333334e-05,
      "loss": 0.4077,
      "step": 1190
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.55078125,
      "learning_rate": 3.406666666666667e-05,
      "loss": 0.3616,
      "step": 1195
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.5,
      "learning_rate": 3.4000000000000007e-05,
      "loss": 0.3912,
      "step": 1200
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.443359375,
      "learning_rate": 3.3933333333333336e-05,
      "loss": 0.3804,
      "step": 1205
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.443359375,
      "learning_rate": 3.3866666666666665e-05,
      "loss": 0.4386,
      "step": 1210
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.5625,
      "learning_rate": 3.38e-05,
      "loss": 0.4348,
      "step": 1215
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.546875,
      "learning_rate": 3.373333333333333e-05,
      "loss": 0.4551,
      "step": 1220
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.546875,
      "learning_rate": 3.366666666666667e-05,
      "loss": 0.3932,
      "step": 1225
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.59765625,
      "learning_rate": 3.3600000000000004e-05,
      "loss": 0.3933,
      "step": 1230
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.474609375,
      "learning_rate": 3.353333333333333e-05,
      "loss": 0.3892,
      "step": 1235
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.515625,
      "learning_rate": 3.346666666666667e-05,
      "loss": 0.3883,
      "step": 1240
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.5078125,
      "learning_rate": 3.3400000000000005e-05,
      "loss": 0.4004,
      "step": 1245
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.43359375,
      "learning_rate": 3.3333333333333335e-05,
      "loss": 0.3852,
      "step": 1250
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.498046875,
      "learning_rate": 3.326666666666667e-05,
      "loss": 0.4302,
      "step": 1255
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.53515625,
      "learning_rate": 3.32e-05,
      "loss": 0.4149,
      "step": 1260
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.482421875,
      "learning_rate": 3.313333333333333e-05,
      "loss": 0.3778,
      "step": 1265
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.5390625,
      "learning_rate": 3.3066666666666666e-05,
      "loss": 0.4251,
      "step": 1270
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.546875,
      "learning_rate": 3.3e-05,
      "loss": 0.4411,
      "step": 1275
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.455078125,
      "learning_rate": 3.293333333333333e-05,
      "loss": 0.3766,
      "step": 1280
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.4921875,
      "learning_rate": 3.286666666666667e-05,
      "loss": 0.3738,
      "step": 1285
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.55859375,
      "learning_rate": 3.2800000000000004e-05,
      "loss": 0.3947,
      "step": 1290
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.4296875,
      "learning_rate": 3.2733333333333334e-05,
      "loss": 0.3263,
      "step": 1295
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.5078125,
      "learning_rate": 3.266666666666667e-05,
      "loss": 0.4052,
      "step": 1300
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.451171875,
      "learning_rate": 3.26e-05,
      "loss": 0.424,
      "step": 1305
    },
    {
      "epoch": 1.05,
      "grad_norm": 0.59765625,
      "learning_rate": 3.253333333333333e-05,
      "loss": 0.3834,
      "step": 1310
    },
    {
      "epoch": 1.05,
      "grad_norm": 0.41796875,
      "learning_rate": 3.2466666666666665e-05,
      "loss": 0.3904,
      "step": 1315
    },
    {
      "epoch": 1.06,
      "grad_norm": 0.4921875,
      "learning_rate": 3.24e-05,
      "loss": 0.4097,
      "step": 1320
    },
    {
      "epoch": 1.06,
      "grad_norm": 0.4375,
      "learning_rate": 3.233333333333333e-05,
      "loss": 0.3705,
      "step": 1325
    },
    {
      "epoch": 1.06,
      "grad_norm": 0.54296875,
      "learning_rate": 3.226666666666667e-05,
      "loss": 0.3928,
      "step": 1330
    },
    {
      "epoch": 1.07,
      "grad_norm": 0.47265625,
      "learning_rate": 3.2200000000000003e-05,
      "loss": 0.3835,
      "step": 1335
    },
    {
      "epoch": 1.07,
      "grad_norm": 0.474609375,
      "learning_rate": 3.213333333333334e-05,
      "loss": 0.3785,
      "step": 1340
    },
    {
      "epoch": 1.08,
      "grad_norm": 0.50390625,
      "learning_rate": 3.206666666666667e-05,
      "loss": 0.415,
      "step": 1345
    },
    {
      "epoch": 1.08,
      "grad_norm": 0.66796875,
      "learning_rate": 3.2000000000000005e-05,
      "loss": 0.4157,
      "step": 1350
    },
    {
      "epoch": 1.08,
      "grad_norm": 0.5546875,
      "learning_rate": 3.1933333333333335e-05,
      "loss": 0.3599,
      "step": 1355
    },
    {
      "epoch": 1.09,
      "grad_norm": 0.63671875,
      "learning_rate": 3.1866666666666664e-05,
      "loss": 0.4259,
      "step": 1360
    },
    {
      "epoch": 1.09,
      "grad_norm": 0.515625,
      "learning_rate": 3.18e-05,
      "loss": 0.3781,
      "step": 1365
    },
    {
      "epoch": 1.1,
      "grad_norm": 1.28125,
      "learning_rate": 3.173333333333334e-05,
      "loss": 0.389,
      "step": 1370
    },
    {
      "epoch": 1.1,
      "grad_norm": 0.482421875,
      "learning_rate": 3.1666666666666666e-05,
      "loss": 0.3813,
      "step": 1375
    },
    {
      "epoch": 1.1,
      "grad_norm": 0.6484375,
      "learning_rate": 3.16e-05,
      "loss": 0.4074,
      "step": 1380
    },
    {
      "epoch": 1.11,
      "grad_norm": 0.478515625,
      "learning_rate": 3.153333333333334e-05,
      "loss": 0.3664,
      "step": 1385
    },
    {
      "epoch": 1.11,
      "grad_norm": 0.455078125,
      "learning_rate": 3.146666666666667e-05,
      "loss": 0.4126,
      "step": 1390
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.5078125,
      "learning_rate": 3.1400000000000004e-05,
      "loss": 0.3856,
      "step": 1395
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.5078125,
      "learning_rate": 3.1333333333333334e-05,
      "loss": 0.3764,
      "step": 1400
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.54296875,
      "learning_rate": 3.126666666666666e-05,
      "loss": 0.4342,
      "step": 1405
    },
    {
      "epoch": 1.13,
      "grad_norm": 0.52734375,
      "learning_rate": 3.12e-05,
      "loss": 0.3779,
      "step": 1410
    },
    {
      "epoch": 1.13,
      "grad_norm": 0.392578125,
      "learning_rate": 3.1133333333333336e-05,
      "loss": 0.3939,
      "step": 1415
    },
    {
      "epoch": 1.14,
      "grad_norm": 0.412109375,
      "learning_rate": 3.1066666666666665e-05,
      "loss": 0.3842,
      "step": 1420
    },
    {
      "epoch": 1.14,
      "grad_norm": 0.578125,
      "learning_rate": 3.1e-05,
      "loss": 0.3706,
      "step": 1425
    },
    {
      "epoch": 1.14,
      "grad_norm": 0.4453125,
      "learning_rate": 3.093333333333334e-05,
      "loss": 0.3718,
      "step": 1430
    },
    {
      "epoch": 1.15,
      "grad_norm": 0.5078125,
      "learning_rate": 3.086666666666667e-05,
      "loss": 0.4023,
      "step": 1435
    },
    {
      "epoch": 1.15,
      "grad_norm": 0.6953125,
      "learning_rate": 3.08e-05,
      "loss": 0.4203,
      "step": 1440
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.47265625,
      "learning_rate": 3.073333333333334e-05,
      "loss": 0.4339,
      "step": 1445
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.474609375,
      "learning_rate": 3.066666666666667e-05,
      "loss": 0.3722,
      "step": 1450
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.48046875,
      "learning_rate": 3.06e-05,
      "loss": 0.3646,
      "step": 1455
    },
    {
      "epoch": 1.17,
      "grad_norm": 0.52734375,
      "learning_rate": 3.0533333333333335e-05,
      "loss": 0.3892,
      "step": 1460
    },
    {
      "epoch": 1.17,
      "grad_norm": 0.5234375,
      "learning_rate": 3.0466666666666664e-05,
      "loss": 0.397,
      "step": 1465
    },
    {
      "epoch": 1.18,
      "grad_norm": 0.609375,
      "learning_rate": 3.04e-05,
      "loss": 0.4058,
      "step": 1470
    },
    {
      "epoch": 1.18,
      "grad_norm": 0.4453125,
      "learning_rate": 3.0333333333333337e-05,
      "loss": 0.3698,
      "step": 1475
    },
    {
      "epoch": 1.18,
      "grad_norm": 0.49609375,
      "learning_rate": 3.0266666666666666e-05,
      "loss": 0.3931,
      "step": 1480
    },
    {
      "epoch": 1.19,
      "grad_norm": 0.5390625,
      "learning_rate": 3.02e-05,
      "loss": 0.3474,
      "step": 1485
    },
    {
      "epoch": 1.19,
      "grad_norm": 0.61328125,
      "learning_rate": 3.0133333333333335e-05,
      "loss": 0.3824,
      "step": 1490
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.48828125,
      "learning_rate": 3.006666666666667e-05,
      "loss": 0.4086,
      "step": 1495
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.5,
      "learning_rate": 3e-05,
      "loss": 0.4153,
      "step": 1500
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.89453125,
      "learning_rate": 2.9933333333333337e-05,
      "loss": 0.4068,
      "step": 1505
    },
    {
      "epoch": 1.21,
      "grad_norm": 0.59765625,
      "learning_rate": 2.986666666666667e-05,
      "loss": 0.4419,
      "step": 1510
    },
    {
      "epoch": 1.21,
      "grad_norm": 0.419921875,
      "learning_rate": 2.98e-05,
      "loss": 0.3747,
      "step": 1515
    },
    {
      "epoch": 1.22,
      "grad_norm": 0.490234375,
      "learning_rate": 2.9733333333333336e-05,
      "loss": 0.3705,
      "step": 1520
    },
    {
      "epoch": 1.22,
      "grad_norm": 0.53125,
      "learning_rate": 2.9666666666666672e-05,
      "loss": 0.3104,
      "step": 1525
    },
    {
      "epoch": 1.22,
      "grad_norm": 0.45703125,
      "learning_rate": 2.96e-05,
      "loss": 0.4429,
      "step": 1530
    },
    {
      "epoch": 1.23,
      "grad_norm": 0.451171875,
      "learning_rate": 2.9533333333333334e-05,
      "loss": 0.427,
      "step": 1535
    },
    {
      "epoch": 1.23,
      "grad_norm": 0.50390625,
      "learning_rate": 2.946666666666667e-05,
      "loss": 0.3482,
      "step": 1540
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.490234375,
      "learning_rate": 2.94e-05,
      "loss": 0.4836,
      "step": 1545
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.419921875,
      "learning_rate": 2.9333333333333336e-05,
      "loss": 0.4046,
      "step": 1550
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.5390625,
      "learning_rate": 2.926666666666667e-05,
      "loss": 0.4095,
      "step": 1555
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.44140625,
      "learning_rate": 2.9199999999999998e-05,
      "loss": 0.4089,
      "step": 1560
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.439453125,
      "learning_rate": 2.9133333333333334e-05,
      "loss": 0.3506,
      "step": 1565
    },
    {
      "epoch": 1.26,
      "grad_norm": 0.51953125,
      "learning_rate": 2.906666666666667e-05,
      "loss": 0.4138,
      "step": 1570
    },
    {
      "epoch": 1.26,
      "grad_norm": 0.431640625,
      "learning_rate": 2.9e-05,
      "loss": 0.3647,
      "step": 1575
    },
    {
      "epoch": 1.26,
      "grad_norm": 0.349609375,
      "learning_rate": 2.8933333333333333e-05,
      "loss": 0.3696,
      "step": 1580
    },
    {
      "epoch": 1.27,
      "grad_norm": 0.5625,
      "learning_rate": 2.886666666666667e-05,
      "loss": 0.3899,
      "step": 1585
    },
    {
      "epoch": 1.27,
      "grad_norm": 0.4453125,
      "learning_rate": 2.88e-05,
      "loss": 0.3596,
      "step": 1590
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.55078125,
      "learning_rate": 2.8733333333333335e-05,
      "loss": 0.3649,
      "step": 1595
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.40234375,
      "learning_rate": 2.8666666666666668e-05,
      "loss": 0.413,
      "step": 1600
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.4921875,
      "learning_rate": 2.86e-05,
      "loss": 0.379,
      "step": 1605
    },
    {
      "epoch": 1.29,
      "grad_norm": 0.482421875,
      "learning_rate": 2.8533333333333333e-05,
      "loss": 0.3743,
      "step": 1610
    },
    {
      "epoch": 1.29,
      "grad_norm": 0.5234375,
      "learning_rate": 2.846666666666667e-05,
      "loss": 0.3693,
      "step": 1615
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.474609375,
      "learning_rate": 2.84e-05,
      "loss": 0.3366,
      "step": 1620
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.451171875,
      "learning_rate": 2.8333333333333335e-05,
      "loss": 0.4405,
      "step": 1625
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.4375,
      "learning_rate": 2.8266666666666668e-05,
      "loss": 0.4385,
      "step": 1630
    },
    {
      "epoch": 1.31,
      "grad_norm": 0.58203125,
      "learning_rate": 2.8199999999999998e-05,
      "loss": 0.3972,
      "step": 1635
    },
    {
      "epoch": 1.31,
      "grad_norm": 0.48828125,
      "learning_rate": 2.8133333333333334e-05,
      "loss": 0.3761,
      "step": 1640
    },
    {
      "epoch": 1.32,
      "grad_norm": 0.58203125,
      "learning_rate": 2.806666666666667e-05,
      "loss": 0.4093,
      "step": 1645
    },
    {
      "epoch": 1.32,
      "grad_norm": 0.5078125,
      "learning_rate": 2.8000000000000003e-05,
      "loss": 0.3831,
      "step": 1650
    },
    {
      "epoch": 1.32,
      "grad_norm": 0.462890625,
      "learning_rate": 2.7933333333333332e-05,
      "loss": 0.4068,
      "step": 1655
    },
    {
      "epoch": 1.33,
      "grad_norm": 0.470703125,
      "learning_rate": 2.786666666666667e-05,
      "loss": 0.4034,
      "step": 1660
    },
    {
      "epoch": 1.33,
      "grad_norm": 0.55078125,
      "learning_rate": 2.7800000000000005e-05,
      "loss": 0.3921,
      "step": 1665
    },
    {
      "epoch": 1.34,
      "grad_norm": 0.423828125,
      "learning_rate": 2.7733333333333334e-05,
      "loss": 0.3743,
      "step": 1670
    },
    {
      "epoch": 1.34,
      "grad_norm": 0.408203125,
      "learning_rate": 2.7666666666666667e-05,
      "loss": 0.3743,
      "step": 1675
    },
    {
      "epoch": 1.34,
      "grad_norm": 0.6171875,
      "learning_rate": 2.7600000000000003e-05,
      "loss": 0.4004,
      "step": 1680
    },
    {
      "epoch": 1.35,
      "grad_norm": 0.4453125,
      "learning_rate": 2.7533333333333333e-05,
      "loss": 0.3726,
      "step": 1685
    },
    {
      "epoch": 1.35,
      "grad_norm": 0.40625,
      "learning_rate": 2.746666666666667e-05,
      "loss": 0.3471,
      "step": 1690
    },
    {
      "epoch": 1.36,
      "grad_norm": 0.51171875,
      "learning_rate": 2.7400000000000002e-05,
      "loss": 0.4124,
      "step": 1695
    },
    {
      "epoch": 1.36,
      "grad_norm": 0.52734375,
      "learning_rate": 2.733333333333333e-05,
      "loss": 0.3521,
      "step": 1700
    },
    {
      "epoch": 1.36,
      "grad_norm": 0.5390625,
      "learning_rate": 2.7266666666666668e-05,
      "loss": 0.3589,
      "step": 1705
    },
    {
      "epoch": 1.37,
      "grad_norm": 0.48828125,
      "learning_rate": 2.7200000000000004e-05,
      "loss": 0.4298,
      "step": 1710
    },
    {
      "epoch": 1.37,
      "grad_norm": 0.55859375,
      "learning_rate": 2.7133333333333333e-05,
      "loss": 0.4035,
      "step": 1715
    },
    {
      "epoch": 1.38,
      "grad_norm": 0.5546875,
      "learning_rate": 2.706666666666667e-05,
      "loss": 0.3879,
      "step": 1720
    },
    {
      "epoch": 1.38,
      "grad_norm": 0.55859375,
      "learning_rate": 2.7000000000000002e-05,
      "loss": 0.3726,
      "step": 1725
    },
    {
      "epoch": 1.38,
      "grad_norm": 0.38671875,
      "learning_rate": 2.6933333333333332e-05,
      "loss": 0.3964,
      "step": 1730
    },
    {
      "epoch": 1.39,
      "grad_norm": 0.515625,
      "learning_rate": 2.6866666666666668e-05,
      "loss": 0.3964,
      "step": 1735
    },
    {
      "epoch": 1.39,
      "grad_norm": 0.54296875,
      "learning_rate": 2.6800000000000004e-05,
      "loss": 0.3221,
      "step": 1740
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.515625,
      "learning_rate": 2.6733333333333334e-05,
      "loss": 0.3989,
      "step": 1745
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.52734375,
      "learning_rate": 2.6666666666666667e-05,
      "loss": 0.3966,
      "step": 1750
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.5234375,
      "learning_rate": 2.6600000000000003e-05,
      "loss": 0.4165,
      "step": 1755
    },
    {
      "epoch": 1.41,
      "grad_norm": 0.453125,
      "learning_rate": 2.6533333333333332e-05,
      "loss": 0.3709,
      "step": 1760
    },
    {
      "epoch": 1.41,
      "grad_norm": 0.5078125,
      "learning_rate": 2.646666666666667e-05,
      "loss": 0.3744,
      "step": 1765
    },
    {
      "epoch": 1.42,
      "grad_norm": 0.42578125,
      "learning_rate": 2.64e-05,
      "loss": 0.3584,
      "step": 1770
    },
    {
      "epoch": 1.42,
      "grad_norm": 0.484375,
      "learning_rate": 2.633333333333333e-05,
      "loss": 0.3961,
      "step": 1775
    },
    {
      "epoch": 1.42,
      "grad_norm": 0.54296875,
      "learning_rate": 2.6266666666666667e-05,
      "loss": 0.3978,
      "step": 1780
    },
    {
      "epoch": 1.43,
      "grad_norm": 0.427734375,
      "learning_rate": 2.6200000000000003e-05,
      "loss": 0.4134,
      "step": 1785
    },
    {
      "epoch": 1.43,
      "grad_norm": 0.47265625,
      "learning_rate": 2.6133333333333333e-05,
      "loss": 0.387,
      "step": 1790
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.466796875,
      "learning_rate": 2.6066666666666666e-05,
      "loss": 0.4178,
      "step": 1795
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.451171875,
      "learning_rate": 2.6000000000000002e-05,
      "loss": 0.3766,
      "step": 1800
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.5078125,
      "learning_rate": 2.5933333333333338e-05,
      "loss": 0.3967,
      "step": 1805
    },
    {
      "epoch": 1.45,
      "grad_norm": 0.546875,
      "learning_rate": 2.5866666666666667e-05,
      "loss": 0.318,
      "step": 1810
    },
    {
      "epoch": 1.45,
      "grad_norm": 0.58203125,
      "learning_rate": 2.58e-05,
      "loss": 0.3865,
      "step": 1815
    },
    {
      "epoch": 1.46,
      "grad_norm": 0.5,
      "learning_rate": 2.5733333333333337e-05,
      "loss": 0.3415,
      "step": 1820
    },
    {
      "epoch": 1.46,
      "grad_norm": 0.462890625,
      "learning_rate": 2.5666666666666666e-05,
      "loss": 0.4749,
      "step": 1825
    },
    {
      "epoch": 1.46,
      "grad_norm": 0.462890625,
      "learning_rate": 2.5600000000000002e-05,
      "loss": 0.358,
      "step": 1830
    },
    {
      "epoch": 1.47,
      "grad_norm": 0.53125,
      "learning_rate": 2.553333333333334e-05,
      "loss": 0.3964,
      "step": 1835
    },
    {
      "epoch": 1.47,
      "grad_norm": 0.5390625,
      "learning_rate": 2.5466666666666668e-05,
      "loss": 0.2922,
      "step": 1840
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.474609375,
      "learning_rate": 2.54e-05,
      "loss": 0.4176,
      "step": 1845
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.443359375,
      "learning_rate": 2.5333333333333337e-05,
      "loss": 0.4016,
      "step": 1850
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.423828125,
      "learning_rate": 2.5266666666666666e-05,
      "loss": 0.3118,
      "step": 1855
    },
    {
      "epoch": 1.49,
      "grad_norm": 0.5703125,
      "learning_rate": 2.5200000000000003e-05,
      "loss": 0.4198,
      "step": 1860
    },
    {
      "epoch": 1.49,
      "grad_norm": 0.5625,
      "learning_rate": 2.5133333333333336e-05,
      "loss": 0.4079,
      "step": 1865
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.5078125,
      "learning_rate": 2.5066666666666665e-05,
      "loss": 0.3871,
      "step": 1870
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.515625,
      "learning_rate": 2.5e-05,
      "loss": 0.395,
      "step": 1875
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.50390625,
      "learning_rate": 2.4933333333333334e-05,
      "loss": 0.3873,
      "step": 1880
    },
    {
      "epoch": 1.51,
      "grad_norm": 0.474609375,
      "learning_rate": 2.486666666666667e-05,
      "loss": 0.4484,
      "step": 1885
    },
    {
      "epoch": 1.51,
      "grad_norm": 0.60546875,
      "learning_rate": 2.48e-05,
      "loss": 0.3836,
      "step": 1890
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.498046875,
      "learning_rate": 2.4733333333333333e-05,
      "loss": 0.3894,
      "step": 1895
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.447265625,
      "learning_rate": 2.466666666666667e-05,
      "loss": 0.2942,
      "step": 1900
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.5390625,
      "learning_rate": 2.46e-05,
      "loss": 0.3722,
      "step": 1905
    },
    {
      "epoch": 1.53,
      "grad_norm": 0.5078125,
      "learning_rate": 2.4533333333333334e-05,
      "loss": 0.4086,
      "step": 1910
    },
    {
      "epoch": 1.53,
      "grad_norm": 0.45703125,
      "learning_rate": 2.4466666666666667e-05,
      "loss": 0.3342,
      "step": 1915
    },
    {
      "epoch": 1.54,
      "grad_norm": 0.451171875,
      "learning_rate": 2.44e-05,
      "loss": 0.397,
      "step": 1920
    },
    {
      "epoch": 1.54,
      "grad_norm": 0.443359375,
      "learning_rate": 2.4333333333333336e-05,
      "loss": 0.4033,
      "step": 1925
    },
    {
      "epoch": 1.54,
      "grad_norm": 0.43359375,
      "learning_rate": 2.426666666666667e-05,
      "loss": 0.3294,
      "step": 1930
    },
    {
      "epoch": 1.55,
      "grad_norm": 0.51953125,
      "learning_rate": 2.4200000000000002e-05,
      "loss": 0.358,
      "step": 1935
    },
    {
      "epoch": 1.55,
      "grad_norm": 0.5390625,
      "learning_rate": 2.4133333333333335e-05,
      "loss": 0.4017,
      "step": 1940
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.48046875,
      "learning_rate": 2.4066666666666668e-05,
      "loss": 0.3695,
      "step": 1945
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.408203125,
      "learning_rate": 2.4e-05,
      "loss": 0.3755,
      "step": 1950
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.5078125,
      "learning_rate": 2.3933333333333337e-05,
      "loss": 0.3793,
      "step": 1955
    },
    {
      "epoch": 1.57,
      "grad_norm": 0.447265625,
      "learning_rate": 2.3866666666666666e-05,
      "loss": 0.3978,
      "step": 1960
    },
    {
      "epoch": 1.57,
      "grad_norm": 0.421875,
      "learning_rate": 2.38e-05,
      "loss": 0.3894,
      "step": 1965
    },
    {
      "epoch": 1.58,
      "grad_norm": 0.482421875,
      "learning_rate": 2.3733333333333335e-05,
      "loss": 0.4035,
      "step": 1970
    },
    {
      "epoch": 1.58,
      "grad_norm": 0.55859375,
      "learning_rate": 2.3666666666666668e-05,
      "loss": 0.3628,
      "step": 1975
    },
    {
      "epoch": 1.58,
      "grad_norm": 0.458984375,
      "learning_rate": 2.36e-05,
      "loss": 0.3591,
      "step": 1980
    },
    {
      "epoch": 1.59,
      "grad_norm": 0.498046875,
      "learning_rate": 2.3533333333333334e-05,
      "loss": 0.36,
      "step": 1985
    },
    {
      "epoch": 1.59,
      "grad_norm": 0.4609375,
      "learning_rate": 2.3466666666666667e-05,
      "loss": 0.4095,
      "step": 1990
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.458984375,
      "learning_rate": 2.3400000000000003e-05,
      "loss": 0.3983,
      "step": 1995
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.515625,
      "learning_rate": 2.3333333333333336e-05,
      "loss": 0.4123,
      "step": 2000
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.57421875,
      "learning_rate": 2.326666666666667e-05,
      "loss": 0.3933,
      "step": 2005
    },
    {
      "epoch": 1.61,
      "grad_norm": 0.470703125,
      "learning_rate": 2.32e-05,
      "loss": 0.3902,
      "step": 2010
    },
    {
      "epoch": 1.61,
      "grad_norm": 0.49609375,
      "learning_rate": 2.3133333333333334e-05,
      "loss": 0.3646,
      "step": 2015
    },
    {
      "epoch": 1.62,
      "grad_norm": 0.5390625,
      "learning_rate": 2.3066666666666667e-05,
      "loss": 0.3843,
      "step": 2020
    },
    {
      "epoch": 1.62,
      "grad_norm": 0.5625,
      "learning_rate": 2.3000000000000003e-05,
      "loss": 0.4309,
      "step": 2025
    },
    {
      "epoch": 1.62,
      "grad_norm": 0.5234375,
      "learning_rate": 2.2933333333333333e-05,
      "loss": 0.4213,
      "step": 2030
    },
    {
      "epoch": 1.63,
      "grad_norm": 0.49609375,
      "learning_rate": 2.2866666666666666e-05,
      "loss": 0.4041,
      "step": 2035
    },
    {
      "epoch": 1.63,
      "grad_norm": 0.5234375,
      "learning_rate": 2.2800000000000002e-05,
      "loss": 0.418,
      "step": 2040
    },
    {
      "epoch": 1.64,
      "grad_norm": 0.609375,
      "learning_rate": 2.2733333333333335e-05,
      "loss": 0.3603,
      "step": 2045
    },
    {
      "epoch": 1.64,
      "grad_norm": 0.5234375,
      "learning_rate": 2.2666666666666668e-05,
      "loss": 0.363,
      "step": 2050
    },
    {
      "epoch": 1.64,
      "grad_norm": 0.4609375,
      "learning_rate": 2.26e-05,
      "loss": 0.3981,
      "step": 2055
    },
    {
      "epoch": 1.65,
      "grad_norm": 0.5703125,
      "learning_rate": 2.2533333333333333e-05,
      "loss": 0.342,
      "step": 2060
    },
    {
      "epoch": 1.65,
      "grad_norm": 0.41796875,
      "learning_rate": 2.2466666666666666e-05,
      "loss": 0.3872,
      "step": 2065
    },
    {
      "epoch": 1.66,
      "grad_norm": 0.498046875,
      "learning_rate": 2.2400000000000002e-05,
      "loss": 0.3192,
      "step": 2070
    },
    {
      "epoch": 1.66,
      "grad_norm": 0.482421875,
      "learning_rate": 2.2333333333333335e-05,
      "loss": 0.3663,
      "step": 2075
    },
    {
      "epoch": 1.66,
      "grad_norm": 0.482421875,
      "learning_rate": 2.2266666666666668e-05,
      "loss": 0.3498,
      "step": 2080
    },
    {
      "epoch": 1.67,
      "grad_norm": 0.58984375,
      "learning_rate": 2.22e-05,
      "loss": 0.3775,
      "step": 2085
    },
    {
      "epoch": 1.67,
      "grad_norm": 0.490234375,
      "learning_rate": 2.2133333333333334e-05,
      "loss": 0.4117,
      "step": 2090
    },
    {
      "epoch": 1.68,
      "grad_norm": 0.4609375,
      "learning_rate": 2.206666666666667e-05,
      "loss": 0.3947,
      "step": 2095
    },
    {
      "epoch": 1.68,
      "grad_norm": 0.53125,
      "learning_rate": 2.2000000000000003e-05,
      "loss": 0.3207,
      "step": 2100
    },
    {
      "epoch": 1.68,
      "grad_norm": 0.453125,
      "learning_rate": 2.1933333333333332e-05,
      "loss": 0.3888,
      "step": 2105
    },
    {
      "epoch": 1.69,
      "grad_norm": 0.423828125,
      "learning_rate": 2.186666666666667e-05,
      "loss": 0.4056,
      "step": 2110
    },
    {
      "epoch": 1.69,
      "grad_norm": 0.53515625,
      "learning_rate": 2.18e-05,
      "loss": 0.4146,
      "step": 2115
    },
    {
      "epoch": 1.7,
      "grad_norm": 0.4765625,
      "learning_rate": 2.1733333333333334e-05,
      "loss": 0.4408,
      "step": 2120
    },
    {
      "epoch": 1.7,
      "grad_norm": 0.51171875,
      "learning_rate": 2.1666666666666667e-05,
      "loss": 0.3733,
      "step": 2125
    },
    {
      "epoch": 1.7,
      "grad_norm": 0.52734375,
      "learning_rate": 2.16e-05,
      "loss": 0.3802,
      "step": 2130
    },
    {
      "epoch": 1.71,
      "grad_norm": 0.57421875,
      "learning_rate": 2.1533333333333333e-05,
      "loss": 0.3298,
      "step": 2135
    },
    {
      "epoch": 1.71,
      "grad_norm": 0.5546875,
      "learning_rate": 2.146666666666667e-05,
      "loss": 0.404,
      "step": 2140
    },
    {
      "epoch": 1.72,
      "grad_norm": 0.4921875,
      "learning_rate": 2.1400000000000002e-05,
      "loss": 0.4258,
      "step": 2145
    },
    {
      "epoch": 1.72,
      "grad_norm": 0.455078125,
      "learning_rate": 2.1333333333333335e-05,
      "loss": 0.3781,
      "step": 2150
    },
    {
      "epoch": 1.72,
      "grad_norm": 0.46875,
      "learning_rate": 2.1266666666666667e-05,
      "loss": 0.3883,
      "step": 2155
    },
    {
      "epoch": 1.73,
      "grad_norm": 0.431640625,
      "learning_rate": 2.12e-05,
      "loss": 0.3659,
      "step": 2160
    },
    {
      "epoch": 1.73,
      "grad_norm": 0.4921875,
      "learning_rate": 2.1133333333333337e-05,
      "loss": 0.3912,
      "step": 2165
    },
    {
      "epoch": 1.74,
      "grad_norm": 0.50390625,
      "learning_rate": 2.106666666666667e-05,
      "loss": 0.4308,
      "step": 2170
    },
    {
      "epoch": 1.74,
      "grad_norm": 0.380859375,
      "learning_rate": 2.1e-05,
      "loss": 0.3526,
      "step": 2175
    },
    {
      "epoch": 1.74,
      "grad_norm": 0.3984375,
      "learning_rate": 2.0933333333333335e-05,
      "loss": 0.3919,
      "step": 2180
    },
    {
      "epoch": 1.75,
      "grad_norm": 0.458984375,
      "learning_rate": 2.0866666666666668e-05,
      "loss": 0.382,
      "step": 2185
    },
    {
      "epoch": 1.75,
      "grad_norm": 0.50390625,
      "learning_rate": 2.08e-05,
      "loss": 0.4055,
      "step": 2190
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.4921875,
      "learning_rate": 2.0733333333333334e-05,
      "loss": 0.4259,
      "step": 2195
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.42578125,
      "learning_rate": 2.0666666666666666e-05,
      "loss": 0.3833,
      "step": 2200
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.5,
      "learning_rate": 2.06e-05,
      "loss": 0.4041,
      "step": 2205
    },
    {
      "epoch": 1.77,
      "grad_norm": 0.53125,
      "learning_rate": 2.0533333333333336e-05,
      "loss": 0.425,
      "step": 2210
    },
    {
      "epoch": 1.77,
      "grad_norm": 0.59375,
      "learning_rate": 2.046666666666667e-05,
      "loss": 0.3447,
      "step": 2215
    },
    {
      "epoch": 1.78,
      "grad_norm": 0.53515625,
      "learning_rate": 2.04e-05,
      "loss": 0.3998,
      "step": 2220
    },
    {
      "epoch": 1.78,
      "grad_norm": 0.51953125,
      "learning_rate": 2.0333333333333334e-05,
      "loss": 0.4085,
      "step": 2225
    },
    {
      "epoch": 1.78,
      "grad_norm": 0.51953125,
      "learning_rate": 2.0266666666666667e-05,
      "loss": 0.3791,
      "step": 2230
    },
    {
      "epoch": 1.79,
      "grad_norm": 0.4921875,
      "learning_rate": 2.0200000000000003e-05,
      "loss": 0.3762,
      "step": 2235
    },
    {
      "epoch": 1.79,
      "grad_norm": 0.57421875,
      "learning_rate": 2.0133333333333336e-05,
      "loss": 0.3537,
      "step": 2240
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.482421875,
      "learning_rate": 2.0066666666666665e-05,
      "loss": 0.3803,
      "step": 2245
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.515625,
      "learning_rate": 2e-05,
      "loss": 0.3718,
      "step": 2250
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.427734375,
      "learning_rate": 1.9933333333333334e-05,
      "loss": 0.3216,
      "step": 2255
    },
    {
      "epoch": 1.81,
      "grad_norm": 0.51953125,
      "learning_rate": 1.9866666666666667e-05,
      "loss": 0.3551,
      "step": 2260
    },
    {
      "epoch": 1.81,
      "grad_norm": 0.51953125,
      "learning_rate": 1.9800000000000004e-05,
      "loss": 0.3815,
      "step": 2265
    },
    {
      "epoch": 1.82,
      "grad_norm": 0.61328125,
      "learning_rate": 1.9733333333333333e-05,
      "loss": 0.3684,
      "step": 2270
    },
    {
      "epoch": 1.82,
      "grad_norm": 0.57421875,
      "learning_rate": 1.9666666666666666e-05,
      "loss": 0.3962,
      "step": 2275
    },
    {
      "epoch": 1.82,
      "grad_norm": 0.578125,
      "learning_rate": 1.9600000000000002e-05,
      "loss": 0.3701,
      "step": 2280
    },
    {
      "epoch": 1.83,
      "grad_norm": 0.51171875,
      "learning_rate": 1.9533333333333335e-05,
      "loss": 0.3663,
      "step": 2285
    },
    {
      "epoch": 1.83,
      "grad_norm": 0.5625,
      "learning_rate": 1.9466666666666668e-05,
      "loss": 0.4577,
      "step": 2290
    },
    {
      "epoch": 1.84,
      "grad_norm": 0.546875,
      "learning_rate": 1.94e-05,
      "loss": 0.4308,
      "step": 2295
    },
    {
      "epoch": 1.84,
      "grad_norm": 0.46484375,
      "learning_rate": 1.9333333333333333e-05,
      "loss": 0.3999,
      "step": 2300
    },
    {
      "epoch": 1.84,
      "grad_norm": 0.55859375,
      "learning_rate": 1.926666666666667e-05,
      "loss": 0.3436,
      "step": 2305
    },
    {
      "epoch": 1.85,
      "grad_norm": 0.5234375,
      "learning_rate": 1.9200000000000003e-05,
      "loss": 0.358,
      "step": 2310
    },
    {
      "epoch": 1.85,
      "grad_norm": 0.515625,
      "learning_rate": 1.9133333333333332e-05,
      "loss": 0.4135,
      "step": 2315
    },
    {
      "epoch": 1.86,
      "grad_norm": 0.498046875,
      "learning_rate": 1.9066666666666668e-05,
      "loss": 0.3359,
      "step": 2320
    },
    {
      "epoch": 1.86,
      "grad_norm": 0.54296875,
      "learning_rate": 1.9e-05,
      "loss": 0.3867,
      "step": 2325
    },
    {
      "epoch": 1.86,
      "grad_norm": 0.494140625,
      "learning_rate": 1.8933333333333334e-05,
      "loss": 0.4313,
      "step": 2330
    },
    {
      "epoch": 1.87,
      "grad_norm": 0.490234375,
      "learning_rate": 1.886666666666667e-05,
      "loss": 0.3819,
      "step": 2335
    },
    {
      "epoch": 1.87,
      "grad_norm": 0.6171875,
      "learning_rate": 1.88e-05,
      "loss": 0.3746,
      "step": 2340
    },
    {
      "epoch": 1.88,
      "grad_norm": 0.447265625,
      "learning_rate": 1.8733333333333332e-05,
      "loss": 0.3776,
      "step": 2345
    },
    {
      "epoch": 1.88,
      "grad_norm": 0.625,
      "learning_rate": 1.866666666666667e-05,
      "loss": 0.4161,
      "step": 2350
    },
    {
      "epoch": 1.88,
      "grad_norm": 0.6015625,
      "learning_rate": 1.86e-05,
      "loss": 0.3716,
      "step": 2355
    },
    {
      "epoch": 1.89,
      "grad_norm": 0.5078125,
      "learning_rate": 1.8533333333333334e-05,
      "loss": 0.3859,
      "step": 2360
    },
    {
      "epoch": 1.89,
      "grad_norm": 0.478515625,
      "learning_rate": 1.8466666666666667e-05,
      "loss": 0.3864,
      "step": 2365
    },
    {
      "epoch": 1.9,
      "grad_norm": 0.470703125,
      "learning_rate": 1.84e-05,
      "loss": 0.3767,
      "step": 2370
    },
    {
      "epoch": 1.9,
      "grad_norm": 0.6171875,
      "learning_rate": 1.8333333333333333e-05,
      "loss": 0.3733,
      "step": 2375
    },
    {
      "epoch": 1.9,
      "grad_norm": 0.66796875,
      "learning_rate": 1.826666666666667e-05,
      "loss": 0.3917,
      "step": 2380
    },
    {
      "epoch": 1.91,
      "grad_norm": 0.482421875,
      "learning_rate": 1.8200000000000002e-05,
      "loss": 0.3914,
      "step": 2385
    },
    {
      "epoch": 1.91,
      "grad_norm": 0.51953125,
      "learning_rate": 1.8133333333333335e-05,
      "loss": 0.3644,
      "step": 2390
    },
    {
      "epoch": 1.92,
      "grad_norm": 0.46875,
      "learning_rate": 1.8066666666666668e-05,
      "loss": 0.3805,
      "step": 2395
    },
    {
      "epoch": 1.92,
      "grad_norm": 0.57421875,
      "learning_rate": 1.8e-05,
      "loss": 0.4318,
      "step": 2400
    },
    {
      "epoch": 1.92,
      "grad_norm": 0.56640625,
      "learning_rate": 1.7933333333333337e-05,
      "loss": 0.3933,
      "step": 2405
    },
    {
      "epoch": 1.93,
      "grad_norm": 0.53125,
      "learning_rate": 1.7866666666666666e-05,
      "loss": 0.3965,
      "step": 2410
    },
    {
      "epoch": 1.93,
      "grad_norm": 0.482421875,
      "learning_rate": 1.78e-05,
      "loss": 0.3603,
      "step": 2415
    },
    {
      "epoch": 1.94,
      "grad_norm": 0.52734375,
      "learning_rate": 1.7733333333333335e-05,
      "loss": 0.3661,
      "step": 2420
    },
    {
      "epoch": 1.94,
      "grad_norm": 0.48046875,
      "learning_rate": 1.7666666666666668e-05,
      "loss": 0.3578,
      "step": 2425
    },
    {
      "epoch": 1.94,
      "grad_norm": 0.58203125,
      "learning_rate": 1.76e-05,
      "loss": 0.3829,
      "step": 2430
    },
    {
      "epoch": 1.95,
      "grad_norm": 0.62109375,
      "learning_rate": 1.7533333333333334e-05,
      "loss": 0.3923,
      "step": 2435
    },
    {
      "epoch": 1.95,
      "grad_norm": 0.498046875,
      "learning_rate": 1.7466666666666667e-05,
      "loss": 0.4599,
      "step": 2440
    },
    {
      "epoch": 1.96,
      "grad_norm": 0.5703125,
      "learning_rate": 1.74e-05,
      "loss": 0.419,
      "step": 2445
    },
    {
      "epoch": 1.96,
      "grad_norm": 0.462890625,
      "learning_rate": 1.7333333333333336e-05,
      "loss": 0.3696,
      "step": 2450
    },
    {
      "epoch": 1.96,
      "grad_norm": 0.453125,
      "learning_rate": 1.726666666666667e-05,
      "loss": 0.3467,
      "step": 2455
    },
    {
      "epoch": 1.97,
      "grad_norm": 0.490234375,
      "learning_rate": 1.7199999999999998e-05,
      "loss": 0.4038,
      "step": 2460
    },
    {
      "epoch": 1.97,
      "grad_norm": 0.46875,
      "learning_rate": 1.7133333333333334e-05,
      "loss": 0.3724,
      "step": 2465
    },
    {
      "epoch": 1.98,
      "grad_norm": 0.53125,
      "learning_rate": 1.7066666666666667e-05,
      "loss": 0.389,
      "step": 2470
    },
    {
      "epoch": 1.98,
      "grad_norm": 0.5078125,
      "learning_rate": 1.7000000000000003e-05,
      "loss": 0.3654,
      "step": 2475
    },
    {
      "epoch": 1.98,
      "grad_norm": 0.58984375,
      "learning_rate": 1.6933333333333333e-05,
      "loss": 0.4074,
      "step": 2480
    },
    {
      "epoch": 1.99,
      "grad_norm": 0.498046875,
      "learning_rate": 1.6866666666666666e-05,
      "loss": 0.3939,
      "step": 2485
    },
    {
      "epoch": 1.99,
      "grad_norm": 0.4453125,
      "learning_rate": 1.6800000000000002e-05,
      "loss": 0.4318,
      "step": 2490
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.466796875,
      "learning_rate": 1.6733333333333335e-05,
      "loss": 0.3719,
      "step": 2495
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.578125,
      "learning_rate": 1.6666666666666667e-05,
      "loss": 0.3397,
      "step": 2500
    }
  ],
  "logging_steps": 5,
  "max_steps": 3750,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "total_flos": 9.467258490853786e+16,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
