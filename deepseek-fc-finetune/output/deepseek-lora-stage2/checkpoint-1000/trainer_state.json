{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.8,
  "eval_steps": 500,
  "global_step": 1000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0,
      "grad_norm": 1.296875,
      "learning_rate": 4.993333333333334e-05,
      "loss": 3.1243,
      "step": 5
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.2109375,
      "learning_rate": 4.986666666666667e-05,
      "loss": 2.9552,
      "step": 10
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.2421875,
      "learning_rate": 4.9800000000000004e-05,
      "loss": 2.4971,
      "step": 15
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.109375,
      "learning_rate": 4.973333333333334e-05,
      "loss": 2.1835,
      "step": 20
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.046875,
      "learning_rate": 4.966666666666667e-05,
      "loss": 1.7747,
      "step": 25
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.828125,
      "learning_rate": 4.96e-05,
      "loss": 1.4143,
      "step": 30
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.828125,
      "learning_rate": 4.9533333333333336e-05,
      "loss": 1.1781,
      "step": 35
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.5625,
      "learning_rate": 4.9466666666666665e-05,
      "loss": 0.9502,
      "step": 40
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.0390625,
      "learning_rate": 4.94e-05,
      "loss": 0.8263,
      "step": 45
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.4765625,
      "learning_rate": 4.933333333333334e-05,
      "loss": 0.7956,
      "step": 50
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.88671875,
      "learning_rate": 4.926666666666667e-05,
      "loss": 0.687,
      "step": 55
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.65625,
      "learning_rate": 4.92e-05,
      "loss": 0.7025,
      "step": 60
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.359375,
      "learning_rate": 4.913333333333334e-05,
      "loss": 0.6375,
      "step": 65
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.4609375,
      "learning_rate": 4.906666666666667e-05,
      "loss": 0.62,
      "step": 70
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.125,
      "learning_rate": 4.9e-05,
      "loss": 0.6082,
      "step": 75
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.0859375,
      "learning_rate": 4.8933333333333335e-05,
      "loss": 0.6,
      "step": 80
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.8984375,
      "learning_rate": 4.886666666666667e-05,
      "loss": 0.6134,
      "step": 85
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.9609375,
      "learning_rate": 4.88e-05,
      "loss": 0.5941,
      "step": 90
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.80078125,
      "learning_rate": 4.8733333333333337e-05,
      "loss": 0.5595,
      "step": 95
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.0,
      "learning_rate": 4.866666666666667e-05,
      "loss": 0.5547,
      "step": 100
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.96875,
      "learning_rate": 4.86e-05,
      "loss": 0.547,
      "step": 105
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.96484375,
      "learning_rate": 4.853333333333334e-05,
      "loss": 0.558,
      "step": 110
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.0078125,
      "learning_rate": 4.8466666666666675e-05,
      "loss": 0.5383,
      "step": 115
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.5078125,
      "learning_rate": 4.8400000000000004e-05,
      "loss": 0.526,
      "step": 120
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.140625,
      "learning_rate": 4.8333333333333334e-05,
      "loss": 0.5107,
      "step": 125
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.84765625,
      "learning_rate": 4.826666666666667e-05,
      "loss": 0.5408,
      "step": 130
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.1171875,
      "learning_rate": 4.82e-05,
      "loss": 0.4986,
      "step": 135
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.91015625,
      "learning_rate": 4.8133333333333336e-05,
      "loss": 0.4926,
      "step": 140
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.015625,
      "learning_rate": 4.806666666666667e-05,
      "loss": 0.5046,
      "step": 145
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.6015625,
      "learning_rate": 4.8e-05,
      "loss": 0.4923,
      "step": 150
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.92578125,
      "learning_rate": 4.793333333333334e-05,
      "loss": 0.5066,
      "step": 155
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.078125,
      "learning_rate": 4.7866666666666674e-05,
      "loss": 0.4037,
      "step": 160
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.375,
      "learning_rate": 4.78e-05,
      "loss": 0.4724,
      "step": 165
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.0234375,
      "learning_rate": 4.773333333333333e-05,
      "loss": 0.4663,
      "step": 170
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.7578125,
      "learning_rate": 4.766666666666667e-05,
      "loss": 0.4671,
      "step": 175
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.78125,
      "learning_rate": 4.76e-05,
      "loss": 0.496,
      "step": 180
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.953125,
      "learning_rate": 4.7533333333333334e-05,
      "loss": 0.4474,
      "step": 185
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.0,
      "learning_rate": 4.746666666666667e-05,
      "loss": 0.461,
      "step": 190
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.8671875,
      "learning_rate": 4.74e-05,
      "loss": 0.5061,
      "step": 195
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.2109375,
      "learning_rate": 4.7333333333333336e-05,
      "loss": 0.4297,
      "step": 200
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.73046875,
      "learning_rate": 4.726666666666667e-05,
      "loss": 0.4767,
      "step": 205
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.8046875,
      "learning_rate": 4.72e-05,
      "loss": 0.4857,
      "step": 210
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.640625,
      "learning_rate": 4.713333333333333e-05,
      "loss": 0.5131,
      "step": 215
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.984375,
      "learning_rate": 4.706666666666667e-05,
      "loss": 0.4899,
      "step": 220
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.796875,
      "learning_rate": 4.7e-05,
      "loss": 0.4179,
      "step": 225
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.69140625,
      "learning_rate": 4.6933333333333333e-05,
      "loss": 0.395,
      "step": 230
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.28125,
      "learning_rate": 4.686666666666667e-05,
      "loss": 0.4415,
      "step": 235
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.6328125,
      "learning_rate": 4.6800000000000006e-05,
      "loss": 0.4984,
      "step": 240
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.1953125,
      "learning_rate": 4.6733333333333335e-05,
      "loss": 0.4358,
      "step": 245
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.97265625,
      "learning_rate": 4.666666666666667e-05,
      "loss": 0.3998,
      "step": 250
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.58984375,
      "learning_rate": 4.660000000000001e-05,
      "loss": 0.3777,
      "step": 255
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.75,
      "learning_rate": 4.653333333333334e-05,
      "loss": 0.4741,
      "step": 260
    },
    {
      "epoch": 0.21,
      "grad_norm": 1.1953125,
      "learning_rate": 4.646666666666667e-05,
      "loss": 0.4387,
      "step": 265
    },
    {
      "epoch": 0.22,
      "grad_norm": 1.1171875,
      "learning_rate": 4.64e-05,
      "loss": 0.4114,
      "step": 270
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.7421875,
      "learning_rate": 4.633333333333333e-05,
      "loss": 0.4181,
      "step": 275
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.765625,
      "learning_rate": 4.626666666666667e-05,
      "loss": 0.497,
      "step": 280
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.9140625,
      "learning_rate": 4.6200000000000005e-05,
      "loss": 0.4533,
      "step": 285
    },
    {
      "epoch": 0.23,
      "grad_norm": 1.15625,
      "learning_rate": 4.6133333333333334e-05,
      "loss": 0.4247,
      "step": 290
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.765625,
      "learning_rate": 4.606666666666667e-05,
      "loss": 0.4975,
      "step": 295
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.9921875,
      "learning_rate": 4.600000000000001e-05,
      "loss": 0.4668,
      "step": 300
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.74609375,
      "learning_rate": 4.5933333333333336e-05,
      "loss": 0.4149,
      "step": 305
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.6171875,
      "learning_rate": 4.5866666666666666e-05,
      "loss": 0.4289,
      "step": 310
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.625,
      "learning_rate": 4.58e-05,
      "loss": 0.3933,
      "step": 315
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.79296875,
      "learning_rate": 4.573333333333333e-05,
      "loss": 0.4191,
      "step": 320
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.94140625,
      "learning_rate": 4.566666666666667e-05,
      "loss": 0.4909,
      "step": 325
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.5625,
      "learning_rate": 4.5600000000000004e-05,
      "loss": 0.4312,
      "step": 330
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.5390625,
      "learning_rate": 4.553333333333333e-05,
      "loss": 0.4889,
      "step": 335
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.671875,
      "learning_rate": 4.546666666666667e-05,
      "loss": 0.4362,
      "step": 340
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.5078125,
      "learning_rate": 4.5400000000000006e-05,
      "loss": 0.4703,
      "step": 345
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.59375,
      "learning_rate": 4.5333333333333335e-05,
      "loss": 0.4252,
      "step": 350
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.8046875,
      "learning_rate": 4.526666666666667e-05,
      "loss": 0.3799,
      "step": 355
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.79296875,
      "learning_rate": 4.52e-05,
      "loss": 0.4168,
      "step": 360
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.64453125,
      "learning_rate": 4.513333333333333e-05,
      "loss": 0.4178,
      "step": 365
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.7890625,
      "learning_rate": 4.5066666666666667e-05,
      "loss": 0.4141,
      "step": 370
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.84765625,
      "learning_rate": 4.5e-05,
      "loss": 0.4114,
      "step": 375
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.66015625,
      "learning_rate": 4.493333333333333e-05,
      "loss": 0.4852,
      "step": 380
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.62890625,
      "learning_rate": 4.486666666666667e-05,
      "loss": 0.4376,
      "step": 385
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.83984375,
      "learning_rate": 4.4800000000000005e-05,
      "loss": 0.4359,
      "step": 390
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.75,
      "learning_rate": 4.473333333333334e-05,
      "loss": 0.4271,
      "step": 395
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.63671875,
      "learning_rate": 4.466666666666667e-05,
      "loss": 0.3678,
      "step": 400
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.6015625,
      "learning_rate": 4.46e-05,
      "loss": 0.4635,
      "step": 405
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.6171875,
      "learning_rate": 4.4533333333333336e-05,
      "loss": 0.4084,
      "step": 410
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.6796875,
      "learning_rate": 4.4466666666666666e-05,
      "loss": 0.3894,
      "step": 415
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.486328125,
      "learning_rate": 4.44e-05,
      "loss": 0.3738,
      "step": 420
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.734375,
      "learning_rate": 4.433333333333334e-05,
      "loss": 0.4118,
      "step": 425
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.75,
      "learning_rate": 4.426666666666667e-05,
      "loss": 0.4458,
      "step": 430
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.5625,
      "learning_rate": 4.4200000000000004e-05,
      "loss": 0.4907,
      "step": 435
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.67578125,
      "learning_rate": 4.413333333333334e-05,
      "loss": 0.3656,
      "step": 440
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.60546875,
      "learning_rate": 4.406666666666667e-05,
      "loss": 0.4188,
      "step": 445
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.7109375,
      "learning_rate": 4.4000000000000006e-05,
      "loss": 0.4579,
      "step": 450
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.53515625,
      "learning_rate": 4.3933333333333335e-05,
      "loss": 0.4405,
      "step": 455
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.078125,
      "learning_rate": 4.3866666666666665e-05,
      "loss": 0.3888,
      "step": 460
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.640625,
      "learning_rate": 4.38e-05,
      "loss": 0.4771,
      "step": 465
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.62890625,
      "learning_rate": 4.373333333333334e-05,
      "loss": 0.4341,
      "step": 470
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.55078125,
      "learning_rate": 4.3666666666666666e-05,
      "loss": 0.4233,
      "step": 475
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.64453125,
      "learning_rate": 4.36e-05,
      "loss": 0.372,
      "step": 480
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.494140625,
      "learning_rate": 4.353333333333334e-05,
      "loss": 0.4438,
      "step": 485
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.76953125,
      "learning_rate": 4.346666666666667e-05,
      "loss": 0.4352,
      "step": 490
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.73046875,
      "learning_rate": 4.3400000000000005e-05,
      "loss": 0.3877,
      "step": 495
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.59765625,
      "learning_rate": 4.3333333333333334e-05,
      "loss": 0.3602,
      "step": 500
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.5859375,
      "learning_rate": 4.3266666666666664e-05,
      "loss": 0.397,
      "step": 505
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.734375,
      "learning_rate": 4.32e-05,
      "loss": 0.4229,
      "step": 510
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.6640625,
      "learning_rate": 4.3133333333333336e-05,
      "loss": 0.424,
      "step": 515
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.5390625,
      "learning_rate": 4.3066666666666665e-05,
      "loss": 0.3886,
      "step": 520
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.796875,
      "learning_rate": 4.3e-05,
      "loss": 0.3997,
      "step": 525
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.53125,
      "learning_rate": 4.293333333333334e-05,
      "loss": 0.3487,
      "step": 530
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.5,
      "learning_rate": 4.286666666666667e-05,
      "loss": 0.382,
      "step": 535
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.66796875,
      "learning_rate": 4.2800000000000004e-05,
      "loss": 0.4081,
      "step": 540
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.68359375,
      "learning_rate": 4.273333333333333e-05,
      "loss": 0.4053,
      "step": 545
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.482421875,
      "learning_rate": 4.266666666666667e-05,
      "loss": 0.4213,
      "step": 550
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.62890625,
      "learning_rate": 4.26e-05,
      "loss": 0.3769,
      "step": 555
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.609375,
      "learning_rate": 4.2533333333333335e-05,
      "loss": 0.4493,
      "step": 560
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.61328125,
      "learning_rate": 4.246666666666667e-05,
      "loss": 0.4213,
      "step": 565
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.55859375,
      "learning_rate": 4.24e-05,
      "loss": 0.3714,
      "step": 570
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.6796875,
      "learning_rate": 4.233333333333334e-05,
      "loss": 0.4597,
      "step": 575
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.5234375,
      "learning_rate": 4.226666666666667e-05,
      "loss": 0.3968,
      "step": 580
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.55078125,
      "learning_rate": 4.22e-05,
      "loss": 0.3647,
      "step": 585
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.5078125,
      "learning_rate": 4.213333333333334e-05,
      "loss": 0.3836,
      "step": 590
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.53515625,
      "learning_rate": 4.206666666666667e-05,
      "loss": 0.4025,
      "step": 595
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.5390625,
      "learning_rate": 4.2e-05,
      "loss": 0.3641,
      "step": 600
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.6171875,
      "learning_rate": 4.1933333333333334e-05,
      "loss": 0.3841,
      "step": 605
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.6171875,
      "learning_rate": 4.186666666666667e-05,
      "loss": 0.4576,
      "step": 610
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.60546875,
      "learning_rate": 4.18e-05,
      "loss": 0.3973,
      "step": 615
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.578125,
      "learning_rate": 4.1733333333333336e-05,
      "loss": 0.3868,
      "step": 620
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.66015625,
      "learning_rate": 4.166666666666667e-05,
      "loss": 0.4058,
      "step": 625
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.609375,
      "learning_rate": 4.16e-05,
      "loss": 0.4172,
      "step": 630
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.63671875,
      "learning_rate": 4.153333333333334e-05,
      "loss": 0.4086,
      "step": 635
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.515625,
      "learning_rate": 4.146666666666667e-05,
      "loss": 0.4419,
      "step": 640
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.58203125,
      "learning_rate": 4.14e-05,
      "loss": 0.3813,
      "step": 645
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.72265625,
      "learning_rate": 4.133333333333333e-05,
      "loss": 0.4212,
      "step": 650
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.1328125,
      "learning_rate": 4.126666666666667e-05,
      "loss": 0.4075,
      "step": 655
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.67578125,
      "learning_rate": 4.12e-05,
      "loss": 0.416,
      "step": 660
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.54296875,
      "learning_rate": 4.1133333333333335e-05,
      "loss": 0.4164,
      "step": 665
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.5078125,
      "learning_rate": 4.106666666666667e-05,
      "loss": 0.3611,
      "step": 670
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.59765625,
      "learning_rate": 4.1e-05,
      "loss": 0.3738,
      "step": 675
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.51953125,
      "learning_rate": 4.093333333333334e-05,
      "loss": 0.4674,
      "step": 680
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.66796875,
      "learning_rate": 4.086666666666667e-05,
      "loss": 0.3711,
      "step": 685
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.5859375,
      "learning_rate": 4.08e-05,
      "loss": 0.4038,
      "step": 690
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.6171875,
      "learning_rate": 4.073333333333333e-05,
      "loss": 0.4243,
      "step": 695
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.65625,
      "learning_rate": 4.066666666666667e-05,
      "loss": 0.4495,
      "step": 700
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.46875,
      "learning_rate": 4.0600000000000004e-05,
      "loss": 0.4513,
      "step": 705
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.54296875,
      "learning_rate": 4.0533333333333334e-05,
      "loss": 0.4274,
      "step": 710
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.54296875,
      "learning_rate": 4.046666666666667e-05,
      "loss": 0.3725,
      "step": 715
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.51953125,
      "learning_rate": 4.0400000000000006e-05,
      "loss": 0.4682,
      "step": 720
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.75,
      "learning_rate": 4.0333333333333336e-05,
      "loss": 0.3894,
      "step": 725
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.46484375,
      "learning_rate": 4.026666666666667e-05,
      "loss": 0.4016,
      "step": 730
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.546875,
      "learning_rate": 4.02e-05,
      "loss": 0.4009,
      "step": 735
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.54296875,
      "learning_rate": 4.013333333333333e-05,
      "loss": 0.3614,
      "step": 740
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.54296875,
      "learning_rate": 4.006666666666667e-05,
      "loss": 0.4344,
      "step": 745
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.5390625,
      "learning_rate": 4e-05,
      "loss": 0.3973,
      "step": 750
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.48828125,
      "learning_rate": 3.993333333333333e-05,
      "loss": 0.4071,
      "step": 755
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.51171875,
      "learning_rate": 3.986666666666667e-05,
      "loss": 0.3759,
      "step": 760
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.5234375,
      "learning_rate": 3.9800000000000005e-05,
      "loss": 0.407,
      "step": 765
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.61328125,
      "learning_rate": 3.9733333333333335e-05,
      "loss": 0.4242,
      "step": 770
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.640625,
      "learning_rate": 3.966666666666667e-05,
      "loss": 0.42,
      "step": 775
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.61328125,
      "learning_rate": 3.960000000000001e-05,
      "loss": 0.4128,
      "step": 780
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.46875,
      "learning_rate": 3.9533333333333337e-05,
      "loss": 0.3931,
      "step": 785
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.62890625,
      "learning_rate": 3.9466666666666666e-05,
      "loss": 0.4225,
      "step": 790
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.79296875,
      "learning_rate": 3.94e-05,
      "loss": 0.4115,
      "step": 795
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.52734375,
      "learning_rate": 3.933333333333333e-05,
      "loss": 0.4237,
      "step": 800
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.9453125,
      "learning_rate": 3.926666666666667e-05,
      "loss": 0.385,
      "step": 805
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.52734375,
      "learning_rate": 3.9200000000000004e-05,
      "loss": 0.3476,
      "step": 810
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.65234375,
      "learning_rate": 3.9133333333333334e-05,
      "loss": 0.3797,
      "step": 815
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.60546875,
      "learning_rate": 3.906666666666667e-05,
      "loss": 0.3423,
      "step": 820
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.53515625,
      "learning_rate": 3.9000000000000006e-05,
      "loss": 0.4131,
      "step": 825
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.70703125,
      "learning_rate": 3.8933333333333336e-05,
      "loss": 0.3941,
      "step": 830
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.49609375,
      "learning_rate": 3.8866666666666665e-05,
      "loss": 0.4403,
      "step": 835
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.6484375,
      "learning_rate": 3.88e-05,
      "loss": 0.3942,
      "step": 840
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.53515625,
      "learning_rate": 3.873333333333333e-05,
      "loss": 0.3629,
      "step": 845
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.4921875,
      "learning_rate": 3.866666666666667e-05,
      "loss": 0.3639,
      "step": 850
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.447265625,
      "learning_rate": 3.86e-05,
      "loss": 0.4552,
      "step": 855
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.5859375,
      "learning_rate": 3.853333333333334e-05,
      "loss": 0.3938,
      "step": 860
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.48046875,
      "learning_rate": 3.846666666666667e-05,
      "loss": 0.3932,
      "step": 865
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.52734375,
      "learning_rate": 3.8400000000000005e-05,
      "loss": 0.3803,
      "step": 870
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.6484375,
      "learning_rate": 3.8333333333333334e-05,
      "loss": 0.3937,
      "step": 875
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.4609375,
      "learning_rate": 3.8266666666666664e-05,
      "loss": 0.3954,
      "step": 880
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.6640625,
      "learning_rate": 3.82e-05,
      "loss": 0.437,
      "step": 885
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.62890625,
      "learning_rate": 3.8133333333333336e-05,
      "loss": 0.3744,
      "step": 890
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.80859375,
      "learning_rate": 3.8066666666666666e-05,
      "loss": 0.4458,
      "step": 895
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.5625,
      "learning_rate": 3.8e-05,
      "loss": 0.4323,
      "step": 900
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.482421875,
      "learning_rate": 3.793333333333334e-05,
      "loss": 0.4156,
      "step": 905
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.439453125,
      "learning_rate": 3.786666666666667e-05,
      "loss": 0.3827,
      "step": 910
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.470703125,
      "learning_rate": 3.7800000000000004e-05,
      "loss": 0.4325,
      "step": 915
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.8125,
      "learning_rate": 3.773333333333334e-05,
      "loss": 0.4014,
      "step": 920
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.984375,
      "learning_rate": 3.766666666666667e-05,
      "loss": 0.3786,
      "step": 925
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.5703125,
      "learning_rate": 3.76e-05,
      "loss": 0.364,
      "step": 930
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.443359375,
      "learning_rate": 3.7533333333333335e-05,
      "loss": 0.3804,
      "step": 935
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.4921875,
      "learning_rate": 3.7466666666666665e-05,
      "loss": 0.3588,
      "step": 940
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.46875,
      "learning_rate": 3.74e-05,
      "loss": 0.3478,
      "step": 945
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.482421875,
      "learning_rate": 3.733333333333334e-05,
      "loss": 0.3856,
      "step": 950
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.546875,
      "learning_rate": 3.726666666666667e-05,
      "loss": 0.4357,
      "step": 955
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.4921875,
      "learning_rate": 3.72e-05,
      "loss": 0.4192,
      "step": 960
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.400390625,
      "learning_rate": 3.713333333333334e-05,
      "loss": 0.3934,
      "step": 965
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.39453125,
      "learning_rate": 3.706666666666667e-05,
      "loss": 0.399,
      "step": 970
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.5625,
      "learning_rate": 3.7e-05,
      "loss": 0.4146,
      "step": 975
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.578125,
      "learning_rate": 3.6933333333333334e-05,
      "loss": 0.3707,
      "step": 980
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.5859375,
      "learning_rate": 3.6866666666666664e-05,
      "loss": 0.3538,
      "step": 985
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.5390625,
      "learning_rate": 3.68e-05,
      "loss": 0.4547,
      "step": 990
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.55859375,
      "learning_rate": 3.6733333333333336e-05,
      "loss": 0.423,
      "step": 995
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.41796875,
      "learning_rate": 3.6666666666666666e-05,
      "loss": 0.4266,
      "step": 1000
    }
  ],
  "logging_steps": 5,
  "max_steps": 3750,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "total_flos": 3.788974857872179e+16,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
