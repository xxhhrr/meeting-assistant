{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.4,
  "eval_steps": 500,
  "global_step": 500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0,
      "grad_norm": 1.296875,
      "learning_rate": 4.993333333333334e-05,
      "loss": 3.1243,
      "step": 5
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.2109375,
      "learning_rate": 4.986666666666667e-05,
      "loss": 2.9552,
      "step": 10
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.2421875,
      "learning_rate": 4.9800000000000004e-05,
      "loss": 2.4971,
      "step": 15
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.109375,
      "learning_rate": 4.973333333333334e-05,
      "loss": 2.1835,
      "step": 20
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.046875,
      "learning_rate": 4.966666666666667e-05,
      "loss": 1.7747,
      "step": 25
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.828125,
      "learning_rate": 4.96e-05,
      "loss": 1.4143,
      "step": 30
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.828125,
      "learning_rate": 4.9533333333333336e-05,
      "loss": 1.1781,
      "step": 35
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.5625,
      "learning_rate": 4.9466666666666665e-05,
      "loss": 0.9502,
      "step": 40
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.0390625,
      "learning_rate": 4.94e-05,
      "loss": 0.8263,
      "step": 45
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.4765625,
      "learning_rate": 4.933333333333334e-05,
      "loss": 0.7956,
      "step": 50
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.88671875,
      "learning_rate": 4.926666666666667e-05,
      "loss": 0.687,
      "step": 55
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.65625,
      "learning_rate": 4.92e-05,
      "loss": 0.7025,
      "step": 60
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.359375,
      "learning_rate": 4.913333333333334e-05,
      "loss": 0.6375,
      "step": 65
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.4609375,
      "learning_rate": 4.906666666666667e-05,
      "loss": 0.62,
      "step": 70
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.125,
      "learning_rate": 4.9e-05,
      "loss": 0.6082,
      "step": 75
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.0859375,
      "learning_rate": 4.8933333333333335e-05,
      "loss": 0.6,
      "step": 80
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.8984375,
      "learning_rate": 4.886666666666667e-05,
      "loss": 0.6134,
      "step": 85
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.9609375,
      "learning_rate": 4.88e-05,
      "loss": 0.5941,
      "step": 90
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.80078125,
      "learning_rate": 4.8733333333333337e-05,
      "loss": 0.5595,
      "step": 95
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.0,
      "learning_rate": 4.866666666666667e-05,
      "loss": 0.5547,
      "step": 100
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.96875,
      "learning_rate": 4.86e-05,
      "loss": 0.547,
      "step": 105
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.96484375,
      "learning_rate": 4.853333333333334e-05,
      "loss": 0.558,
      "step": 110
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.0078125,
      "learning_rate": 4.8466666666666675e-05,
      "loss": 0.5383,
      "step": 115
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.5078125,
      "learning_rate": 4.8400000000000004e-05,
      "loss": 0.526,
      "step": 120
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.140625,
      "learning_rate": 4.8333333333333334e-05,
      "loss": 0.5107,
      "step": 125
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.84765625,
      "learning_rate": 4.826666666666667e-05,
      "loss": 0.5408,
      "step": 130
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.1171875,
      "learning_rate": 4.82e-05,
      "loss": 0.4986,
      "step": 135
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.91015625,
      "learning_rate": 4.8133333333333336e-05,
      "loss": 0.4926,
      "step": 140
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.015625,
      "learning_rate": 4.806666666666667e-05,
      "loss": 0.5046,
      "step": 145
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.6015625,
      "learning_rate": 4.8e-05,
      "loss": 0.4923,
      "step": 150
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.92578125,
      "learning_rate": 4.793333333333334e-05,
      "loss": 0.5066,
      "step": 155
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.078125,
      "learning_rate": 4.7866666666666674e-05,
      "loss": 0.4037,
      "step": 160
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.375,
      "learning_rate": 4.78e-05,
      "loss": 0.4724,
      "step": 165
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.0234375,
      "learning_rate": 4.773333333333333e-05,
      "loss": 0.4663,
      "step": 170
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.7578125,
      "learning_rate": 4.766666666666667e-05,
      "loss": 0.4671,
      "step": 175
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.78125,
      "learning_rate": 4.76e-05,
      "loss": 0.496,
      "step": 180
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.953125,
      "learning_rate": 4.7533333333333334e-05,
      "loss": 0.4474,
      "step": 185
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.0,
      "learning_rate": 4.746666666666667e-05,
      "loss": 0.461,
      "step": 190
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.8671875,
      "learning_rate": 4.74e-05,
      "loss": 0.5061,
      "step": 195
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.2109375,
      "learning_rate": 4.7333333333333336e-05,
      "loss": 0.4297,
      "step": 200
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.73046875,
      "learning_rate": 4.726666666666667e-05,
      "loss": 0.4767,
      "step": 205
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.8046875,
      "learning_rate": 4.72e-05,
      "loss": 0.4857,
      "step": 210
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.640625,
      "learning_rate": 4.713333333333333e-05,
      "loss": 0.5131,
      "step": 215
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.984375,
      "learning_rate": 4.706666666666667e-05,
      "loss": 0.4899,
      "step": 220
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.796875,
      "learning_rate": 4.7e-05,
      "loss": 0.4179,
      "step": 225
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.69140625,
      "learning_rate": 4.6933333333333333e-05,
      "loss": 0.395,
      "step": 230
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.28125,
      "learning_rate": 4.686666666666667e-05,
      "loss": 0.4415,
      "step": 235
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.6328125,
      "learning_rate": 4.6800000000000006e-05,
      "loss": 0.4984,
      "step": 240
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.1953125,
      "learning_rate": 4.6733333333333335e-05,
      "loss": 0.4358,
      "step": 245
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.97265625,
      "learning_rate": 4.666666666666667e-05,
      "loss": 0.3998,
      "step": 250
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.58984375,
      "learning_rate": 4.660000000000001e-05,
      "loss": 0.3777,
      "step": 255
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.75,
      "learning_rate": 4.653333333333334e-05,
      "loss": 0.4741,
      "step": 260
    },
    {
      "epoch": 0.21,
      "grad_norm": 1.1953125,
      "learning_rate": 4.646666666666667e-05,
      "loss": 0.4387,
      "step": 265
    },
    {
      "epoch": 0.22,
      "grad_norm": 1.1171875,
      "learning_rate": 4.64e-05,
      "loss": 0.4114,
      "step": 270
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.7421875,
      "learning_rate": 4.633333333333333e-05,
      "loss": 0.4181,
      "step": 275
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.765625,
      "learning_rate": 4.626666666666667e-05,
      "loss": 0.497,
      "step": 280
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.9140625,
      "learning_rate": 4.6200000000000005e-05,
      "loss": 0.4533,
      "step": 285
    },
    {
      "epoch": 0.23,
      "grad_norm": 1.15625,
      "learning_rate": 4.6133333333333334e-05,
      "loss": 0.4247,
      "step": 290
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.765625,
      "learning_rate": 4.606666666666667e-05,
      "loss": 0.4975,
      "step": 295
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.9921875,
      "learning_rate": 4.600000000000001e-05,
      "loss": 0.4668,
      "step": 300
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.74609375,
      "learning_rate": 4.5933333333333336e-05,
      "loss": 0.4149,
      "step": 305
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.6171875,
      "learning_rate": 4.5866666666666666e-05,
      "loss": 0.4289,
      "step": 310
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.625,
      "learning_rate": 4.58e-05,
      "loss": 0.3933,
      "step": 315
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.79296875,
      "learning_rate": 4.573333333333333e-05,
      "loss": 0.4191,
      "step": 320
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.94140625,
      "learning_rate": 4.566666666666667e-05,
      "loss": 0.4909,
      "step": 325
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.5625,
      "learning_rate": 4.5600000000000004e-05,
      "loss": 0.4312,
      "step": 330
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.5390625,
      "learning_rate": 4.553333333333333e-05,
      "loss": 0.4889,
      "step": 335
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.671875,
      "learning_rate": 4.546666666666667e-05,
      "loss": 0.4362,
      "step": 340
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.5078125,
      "learning_rate": 4.5400000000000006e-05,
      "loss": 0.4703,
      "step": 345
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.59375,
      "learning_rate": 4.5333333333333335e-05,
      "loss": 0.4252,
      "step": 350
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.8046875,
      "learning_rate": 4.526666666666667e-05,
      "loss": 0.3799,
      "step": 355
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.79296875,
      "learning_rate": 4.52e-05,
      "loss": 0.4168,
      "step": 360
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.64453125,
      "learning_rate": 4.513333333333333e-05,
      "loss": 0.4178,
      "step": 365
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.7890625,
      "learning_rate": 4.5066666666666667e-05,
      "loss": 0.4141,
      "step": 370
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.84765625,
      "learning_rate": 4.5e-05,
      "loss": 0.4114,
      "step": 375
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.66015625,
      "learning_rate": 4.493333333333333e-05,
      "loss": 0.4852,
      "step": 380
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.62890625,
      "learning_rate": 4.486666666666667e-05,
      "loss": 0.4376,
      "step": 385
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.83984375,
      "learning_rate": 4.4800000000000005e-05,
      "loss": 0.4359,
      "step": 390
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.75,
      "learning_rate": 4.473333333333334e-05,
      "loss": 0.4271,
      "step": 395
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.63671875,
      "learning_rate": 4.466666666666667e-05,
      "loss": 0.3678,
      "step": 400
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.6015625,
      "learning_rate": 4.46e-05,
      "loss": 0.4635,
      "step": 405
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.6171875,
      "learning_rate": 4.4533333333333336e-05,
      "loss": 0.4084,
      "step": 410
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.6796875,
      "learning_rate": 4.4466666666666666e-05,
      "loss": 0.3894,
      "step": 415
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.486328125,
      "learning_rate": 4.44e-05,
      "loss": 0.3738,
      "step": 420
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.734375,
      "learning_rate": 4.433333333333334e-05,
      "loss": 0.4118,
      "step": 425
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.75,
      "learning_rate": 4.426666666666667e-05,
      "loss": 0.4458,
      "step": 430
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.5625,
      "learning_rate": 4.4200000000000004e-05,
      "loss": 0.4907,
      "step": 435
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.67578125,
      "learning_rate": 4.413333333333334e-05,
      "loss": 0.3656,
      "step": 440
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.60546875,
      "learning_rate": 4.406666666666667e-05,
      "loss": 0.4188,
      "step": 445
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.7109375,
      "learning_rate": 4.4000000000000006e-05,
      "loss": 0.4579,
      "step": 450
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.53515625,
      "learning_rate": 4.3933333333333335e-05,
      "loss": 0.4405,
      "step": 455
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.078125,
      "learning_rate": 4.3866666666666665e-05,
      "loss": 0.3888,
      "step": 460
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.640625,
      "learning_rate": 4.38e-05,
      "loss": 0.4771,
      "step": 465
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.62890625,
      "learning_rate": 4.373333333333334e-05,
      "loss": 0.4341,
      "step": 470
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.55078125,
      "learning_rate": 4.3666666666666666e-05,
      "loss": 0.4233,
      "step": 475
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.64453125,
      "learning_rate": 4.36e-05,
      "loss": 0.372,
      "step": 480
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.494140625,
      "learning_rate": 4.353333333333334e-05,
      "loss": 0.4438,
      "step": 485
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.76953125,
      "learning_rate": 4.346666666666667e-05,
      "loss": 0.4352,
      "step": 490
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.73046875,
      "learning_rate": 4.3400000000000005e-05,
      "loss": 0.3877,
      "step": 495
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.59765625,
      "learning_rate": 4.3333333333333334e-05,
      "loss": 0.3602,
      "step": 500
    }
  ],
  "logging_steps": 5,
  "max_steps": 3750,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "total_flos": 1.9097032625504256e+16,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
