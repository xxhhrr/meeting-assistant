{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.6666666666666665,
  "eval_steps": 500,
  "global_step": 1000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.01,
      "grad_norm": 2.46875,
      "learning_rate": 4.977777777777778e-05,
      "loss": 2.0633,
      "step": 5
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.3984375,
      "learning_rate": 4.955555555555556e-05,
      "loss": 1.6954,
      "step": 10
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.671875,
      "learning_rate": 4.933333333333334e-05,
      "loss": 1.4176,
      "step": 15
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.765625,
      "learning_rate": 4.9111111111111114e-05,
      "loss": 1.0952,
      "step": 20
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.6171875,
      "learning_rate": 4.888888888888889e-05,
      "loss": 0.761,
      "step": 25
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.3671875,
      "learning_rate": 4.866666666666667e-05,
      "loss": 0.4987,
      "step": 30
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.7421875,
      "learning_rate": 4.844444444444445e-05,
      "loss": 0.3189,
      "step": 35
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.74609375,
      "learning_rate": 4.8222222222222225e-05,
      "loss": 0.1894,
      "step": 40
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.62109375,
      "learning_rate": 4.8e-05,
      "loss": 0.1483,
      "step": 45
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.51953125,
      "learning_rate": 4.7777777777777784e-05,
      "loss": 0.1252,
      "step": 50
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.369140625,
      "learning_rate": 4.755555555555556e-05,
      "loss": 0.1137,
      "step": 55
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.70703125,
      "learning_rate": 4.7333333333333336e-05,
      "loss": 0.1066,
      "step": 60
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.59375,
      "learning_rate": 4.711111111111111e-05,
      "loss": 0.1135,
      "step": 65
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.59765625,
      "learning_rate": 4.6888888888888895e-05,
      "loss": 0.1072,
      "step": 70
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.4375,
      "learning_rate": 4.666666666666667e-05,
      "loss": 0.0999,
      "step": 75
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.50390625,
      "learning_rate": 4.644444444444445e-05,
      "loss": 0.1021,
      "step": 80
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.53515625,
      "learning_rate": 4.6222222222222224e-05,
      "loss": 0.0975,
      "step": 85
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.42578125,
      "learning_rate": 4.600000000000001e-05,
      "loss": 0.0941,
      "step": 90
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.50390625,
      "learning_rate": 4.577777777777778e-05,
      "loss": 0.0934,
      "step": 95
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.5390625,
      "learning_rate": 4.555555555555556e-05,
      "loss": 0.0907,
      "step": 100
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.384765625,
      "learning_rate": 4.5333333333333335e-05,
      "loss": 0.0791,
      "step": 105
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.50390625,
      "learning_rate": 4.511111111111112e-05,
      "loss": 0.0826,
      "step": 110
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.5546875,
      "learning_rate": 4.4888888888888894e-05,
      "loss": 0.0854,
      "step": 115
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.412109375,
      "learning_rate": 4.466666666666667e-05,
      "loss": 0.0913,
      "step": 120
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.34765625,
      "learning_rate": 4.4444444444444447e-05,
      "loss": 0.0834,
      "step": 125
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.3515625,
      "learning_rate": 4.422222222222222e-05,
      "loss": 0.0862,
      "step": 130
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.408203125,
      "learning_rate": 4.4000000000000006e-05,
      "loss": 0.0921,
      "step": 135
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.3203125,
      "learning_rate": 4.377777777777778e-05,
      "loss": 0.074,
      "step": 140
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.5703125,
      "learning_rate": 4.355555555555556e-05,
      "loss": 0.0831,
      "step": 145
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.345703125,
      "learning_rate": 4.3333333333333334e-05,
      "loss": 0.0815,
      "step": 150
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.31640625,
      "learning_rate": 4.311111111111111e-05,
      "loss": 0.0832,
      "step": 155
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.318359375,
      "learning_rate": 4.2888888888888886e-05,
      "loss": 0.0839,
      "step": 160
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.6640625,
      "learning_rate": 4.266666666666667e-05,
      "loss": 0.0949,
      "step": 165
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.330078125,
      "learning_rate": 4.2444444444444445e-05,
      "loss": 0.0881,
      "step": 170
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.34375,
      "learning_rate": 4.222222222222222e-05,
      "loss": 0.0873,
      "step": 175
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.36328125,
      "learning_rate": 4.2e-05,
      "loss": 0.0857,
      "step": 180
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.37109375,
      "learning_rate": 4.177777777777778e-05,
      "loss": 0.0859,
      "step": 185
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.37109375,
      "learning_rate": 4.155555555555556e-05,
      "loss": 0.0858,
      "step": 190
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.2890625,
      "learning_rate": 4.133333333333333e-05,
      "loss": 0.0762,
      "step": 195
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.357421875,
      "learning_rate": 4.111111111111111e-05,
      "loss": 0.0814,
      "step": 200
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.373046875,
      "learning_rate": 4.088888888888889e-05,
      "loss": 0.0854,
      "step": 205
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.33203125,
      "learning_rate": 4.066666666666667e-05,
      "loss": 0.0821,
      "step": 210
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.2578125,
      "learning_rate": 4.0444444444444444e-05,
      "loss": 0.0814,
      "step": 215
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.2021484375,
      "learning_rate": 4.022222222222222e-05,
      "loss": 0.0766,
      "step": 220
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.2236328125,
      "learning_rate": 4e-05,
      "loss": 0.0812,
      "step": 225
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.287109375,
      "learning_rate": 3.977777777777778e-05,
      "loss": 0.0755,
      "step": 230
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.37109375,
      "learning_rate": 3.9555555555555556e-05,
      "loss": 0.0822,
      "step": 235
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.30078125,
      "learning_rate": 3.933333333333333e-05,
      "loss": 0.0788,
      "step": 240
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.2333984375,
      "learning_rate": 3.9111111111111115e-05,
      "loss": 0.0814,
      "step": 245
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.294921875,
      "learning_rate": 3.888888888888889e-05,
      "loss": 0.0774,
      "step": 250
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.255859375,
      "learning_rate": 3.866666666666667e-05,
      "loss": 0.0787,
      "step": 255
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.2470703125,
      "learning_rate": 3.844444444444444e-05,
      "loss": 0.0837,
      "step": 260
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.271484375,
      "learning_rate": 3.8222222222222226e-05,
      "loss": 0.0737,
      "step": 265
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.2490234375,
      "learning_rate": 3.8e-05,
      "loss": 0.072,
      "step": 270
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.271484375,
      "learning_rate": 3.777777777777778e-05,
      "loss": 0.0852,
      "step": 275
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.291015625,
      "learning_rate": 3.7555555555555554e-05,
      "loss": 0.0788,
      "step": 280
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.248046875,
      "learning_rate": 3.733333333333334e-05,
      "loss": 0.0814,
      "step": 285
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.2353515625,
      "learning_rate": 3.7111111111111113e-05,
      "loss": 0.0752,
      "step": 290
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.2177734375,
      "learning_rate": 3.688888888888889e-05,
      "loss": 0.0752,
      "step": 295
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.294921875,
      "learning_rate": 3.6666666666666666e-05,
      "loss": 0.0774,
      "step": 300
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.23046875,
      "learning_rate": 3.644444444444445e-05,
      "loss": 0.0803,
      "step": 305
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.212890625,
      "learning_rate": 3.6222222222222225e-05,
      "loss": 0.081,
      "step": 310
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.2490234375,
      "learning_rate": 3.6e-05,
      "loss": 0.0787,
      "step": 315
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.1650390625,
      "learning_rate": 3.577777777777778e-05,
      "loss": 0.0888,
      "step": 320
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.1796875,
      "learning_rate": 3.555555555555556e-05,
      "loss": 0.0734,
      "step": 325
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.396484375,
      "learning_rate": 3.5333333333333336e-05,
      "loss": 0.081,
      "step": 330
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.267578125,
      "learning_rate": 3.511111111111111e-05,
      "loss": 0.0756,
      "step": 335
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.228515625,
      "learning_rate": 3.4888888888888895e-05,
      "loss": 0.0815,
      "step": 340
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.318359375,
      "learning_rate": 3.466666666666667e-05,
      "loss": 0.0756,
      "step": 345
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.2333984375,
      "learning_rate": 3.444444444444445e-05,
      "loss": 0.0808,
      "step": 350
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.328125,
      "learning_rate": 3.4222222222222224e-05,
      "loss": 0.0745,
      "step": 355
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.267578125,
      "learning_rate": 3.4000000000000007e-05,
      "loss": 0.073,
      "step": 360
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.294921875,
      "learning_rate": 3.377777777777778e-05,
      "loss": 0.0772,
      "step": 365
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.291015625,
      "learning_rate": 3.355555555555556e-05,
      "loss": 0.0825,
      "step": 370
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.28515625,
      "learning_rate": 3.3333333333333335e-05,
      "loss": 0.0797,
      "step": 375
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.212890625,
      "learning_rate": 3.311111111111112e-05,
      "loss": 0.0734,
      "step": 380
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.298828125,
      "learning_rate": 3.2888888888888894e-05,
      "loss": 0.0848,
      "step": 385
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.244140625,
      "learning_rate": 3.266666666666667e-05,
      "loss": 0.0782,
      "step": 390
    },
    {
      "epoch": 1.05,
      "grad_norm": 0.31640625,
      "learning_rate": 3.2444444444444446e-05,
      "loss": 0.0748,
      "step": 395
    },
    {
      "epoch": 1.07,
      "grad_norm": 0.234375,
      "learning_rate": 3.222222222222223e-05,
      "loss": 0.0791,
      "step": 400
    },
    {
      "epoch": 1.08,
      "grad_norm": 0.322265625,
      "learning_rate": 3.2000000000000005e-05,
      "loss": 0.0823,
      "step": 405
    },
    {
      "epoch": 1.09,
      "grad_norm": 0.26953125,
      "learning_rate": 3.177777777777778e-05,
      "loss": 0.0766,
      "step": 410
    },
    {
      "epoch": 1.11,
      "grad_norm": 0.205078125,
      "learning_rate": 3.155555555555556e-05,
      "loss": 0.0747,
      "step": 415
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.296875,
      "learning_rate": 3.1333333333333334e-05,
      "loss": 0.0729,
      "step": 420
    },
    {
      "epoch": 1.13,
      "grad_norm": 0.25390625,
      "learning_rate": 3.111111111111111e-05,
      "loss": 0.0822,
      "step": 425
    },
    {
      "epoch": 1.15,
      "grad_norm": 0.30859375,
      "learning_rate": 3.088888888888889e-05,
      "loss": 0.0787,
      "step": 430
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.2080078125,
      "learning_rate": 3.066666666666667e-05,
      "loss": 0.0807,
      "step": 435
    },
    {
      "epoch": 1.17,
      "grad_norm": 0.2392578125,
      "learning_rate": 3.044444444444445e-05,
      "loss": 0.0841,
      "step": 440
    },
    {
      "epoch": 1.19,
      "grad_norm": 0.2119140625,
      "learning_rate": 3.0222222222222225e-05,
      "loss": 0.0733,
      "step": 445
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.337890625,
      "learning_rate": 3e-05,
      "loss": 0.0833,
      "step": 450
    },
    {
      "epoch": 1.21,
      "grad_norm": 0.50390625,
      "learning_rate": 2.9777777777777777e-05,
      "loss": 0.0771,
      "step": 455
    },
    {
      "epoch": 1.23,
      "grad_norm": 0.2060546875,
      "learning_rate": 2.955555555555556e-05,
      "loss": 0.0801,
      "step": 460
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.2060546875,
      "learning_rate": 2.9333333333333336e-05,
      "loss": 0.0709,
      "step": 465
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.2041015625,
      "learning_rate": 2.9111111111111112e-05,
      "loss": 0.0745,
      "step": 470
    },
    {
      "epoch": 1.27,
      "grad_norm": 0.197265625,
      "learning_rate": 2.8888888888888888e-05,
      "loss": 0.079,
      "step": 475
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.2138671875,
      "learning_rate": 2.8666666666666668e-05,
      "loss": 0.0725,
      "step": 480
    },
    {
      "epoch": 1.29,
      "grad_norm": 0.224609375,
      "learning_rate": 2.8444444444444447e-05,
      "loss": 0.0728,
      "step": 485
    },
    {
      "epoch": 1.31,
      "grad_norm": 0.279296875,
      "learning_rate": 2.8222222222222223e-05,
      "loss": 0.0728,
      "step": 490
    },
    {
      "epoch": 1.32,
      "grad_norm": 0.279296875,
      "learning_rate": 2.8000000000000003e-05,
      "loss": 0.0803,
      "step": 495
    },
    {
      "epoch": 1.33,
      "grad_norm": 0.26953125,
      "learning_rate": 2.777777777777778e-05,
      "loss": 0.0805,
      "step": 500
    },
    {
      "epoch": 1.35,
      "grad_norm": 0.2431640625,
      "learning_rate": 2.7555555555555555e-05,
      "loss": 0.0848,
      "step": 505
    },
    {
      "epoch": 1.36,
      "grad_norm": 0.2431640625,
      "learning_rate": 2.733333333333333e-05,
      "loss": 0.0756,
      "step": 510
    },
    {
      "epoch": 1.37,
      "grad_norm": 0.267578125,
      "learning_rate": 2.7111111111111114e-05,
      "loss": 0.0742,
      "step": 515
    },
    {
      "epoch": 1.39,
      "grad_norm": 0.2158203125,
      "learning_rate": 2.688888888888889e-05,
      "loss": 0.0703,
      "step": 520
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.353515625,
      "learning_rate": 2.6666666666666667e-05,
      "loss": 0.0824,
      "step": 525
    },
    {
      "epoch": 1.41,
      "grad_norm": 0.2197265625,
      "learning_rate": 2.6444444444444443e-05,
      "loss": 0.0776,
      "step": 530
    },
    {
      "epoch": 1.43,
      "grad_norm": 0.2275390625,
      "learning_rate": 2.6222222222222226e-05,
      "loss": 0.0795,
      "step": 535
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.259765625,
      "learning_rate": 2.6000000000000002e-05,
      "loss": 0.0738,
      "step": 540
    },
    {
      "epoch": 1.45,
      "grad_norm": 0.19140625,
      "learning_rate": 2.5777777777777778e-05,
      "loss": 0.0755,
      "step": 545
    },
    {
      "epoch": 1.47,
      "grad_norm": 0.2021484375,
      "learning_rate": 2.5555555555555554e-05,
      "loss": 0.0751,
      "step": 550
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.23828125,
      "learning_rate": 2.5333333333333337e-05,
      "loss": 0.0759,
      "step": 555
    },
    {
      "epoch": 1.49,
      "grad_norm": 0.271484375,
      "learning_rate": 2.5111111111111113e-05,
      "loss": 0.0787,
      "step": 560
    },
    {
      "epoch": 1.51,
      "grad_norm": 0.205078125,
      "learning_rate": 2.488888888888889e-05,
      "loss": 0.0761,
      "step": 565
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.271484375,
      "learning_rate": 2.466666666666667e-05,
      "loss": 0.0736,
      "step": 570
    },
    {
      "epoch": 1.53,
      "grad_norm": 0.2275390625,
      "learning_rate": 2.4444444444444445e-05,
      "loss": 0.0838,
      "step": 575
    },
    {
      "epoch": 1.55,
      "grad_norm": 0.232421875,
      "learning_rate": 2.4222222222222224e-05,
      "loss": 0.0701,
      "step": 580
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.21875,
      "learning_rate": 2.4e-05,
      "loss": 0.0726,
      "step": 585
    },
    {
      "epoch": 1.57,
      "grad_norm": 0.20703125,
      "learning_rate": 2.377777777777778e-05,
      "loss": 0.0757,
      "step": 590
    },
    {
      "epoch": 1.59,
      "grad_norm": 0.2197265625,
      "learning_rate": 2.3555555555555556e-05,
      "loss": 0.0738,
      "step": 595
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.251953125,
      "learning_rate": 2.3333333333333336e-05,
      "loss": 0.0761,
      "step": 600
    },
    {
      "epoch": 1.61,
      "grad_norm": 0.232421875,
      "learning_rate": 2.3111111111111112e-05,
      "loss": 0.0727,
      "step": 605
    },
    {
      "epoch": 1.63,
      "grad_norm": 0.267578125,
      "learning_rate": 2.288888888888889e-05,
      "loss": 0.0797,
      "step": 610
    },
    {
      "epoch": 1.64,
      "grad_norm": 0.2158203125,
      "learning_rate": 2.2666666666666668e-05,
      "loss": 0.0816,
      "step": 615
    },
    {
      "epoch": 1.65,
      "grad_norm": 0.2138671875,
      "learning_rate": 2.2444444444444447e-05,
      "loss": 0.0701,
      "step": 620
    },
    {
      "epoch": 1.67,
      "grad_norm": 0.27734375,
      "learning_rate": 2.2222222222222223e-05,
      "loss": 0.0728,
      "step": 625
    },
    {
      "epoch": 1.68,
      "grad_norm": 0.189453125,
      "learning_rate": 2.2000000000000003e-05,
      "loss": 0.0721,
      "step": 630
    },
    {
      "epoch": 1.69,
      "grad_norm": 0.28125,
      "learning_rate": 2.177777777777778e-05,
      "loss": 0.07,
      "step": 635
    },
    {
      "epoch": 1.71,
      "grad_norm": 0.30859375,
      "learning_rate": 2.1555555555555555e-05,
      "loss": 0.0881,
      "step": 640
    },
    {
      "epoch": 1.72,
      "grad_norm": 0.224609375,
      "learning_rate": 2.1333333333333335e-05,
      "loss": 0.0708,
      "step": 645
    },
    {
      "epoch": 1.73,
      "grad_norm": 0.302734375,
      "learning_rate": 2.111111111111111e-05,
      "loss": 0.071,
      "step": 650
    },
    {
      "epoch": 1.75,
      "grad_norm": 0.23046875,
      "learning_rate": 2.088888888888889e-05,
      "loss": 0.0799,
      "step": 655
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.2421875,
      "learning_rate": 2.0666666666666666e-05,
      "loss": 0.0771,
      "step": 660
    },
    {
      "epoch": 1.77,
      "grad_norm": 0.248046875,
      "learning_rate": 2.0444444444444446e-05,
      "loss": 0.075,
      "step": 665
    },
    {
      "epoch": 1.79,
      "grad_norm": 0.2451171875,
      "learning_rate": 2.0222222222222222e-05,
      "loss": 0.0818,
      "step": 670
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.1923828125,
      "learning_rate": 2e-05,
      "loss": 0.0833,
      "step": 675
    },
    {
      "epoch": 1.81,
      "grad_norm": 0.259765625,
      "learning_rate": 1.9777777777777778e-05,
      "loss": 0.0862,
      "step": 680
    },
    {
      "epoch": 1.83,
      "grad_norm": 0.263671875,
      "learning_rate": 1.9555555555555557e-05,
      "loss": 0.0719,
      "step": 685
    },
    {
      "epoch": 1.84,
      "grad_norm": 0.2216796875,
      "learning_rate": 1.9333333333333333e-05,
      "loss": 0.0768,
      "step": 690
    },
    {
      "epoch": 1.85,
      "grad_norm": 0.173828125,
      "learning_rate": 1.9111111111111113e-05,
      "loss": 0.0803,
      "step": 695
    },
    {
      "epoch": 1.87,
      "grad_norm": 0.220703125,
      "learning_rate": 1.888888888888889e-05,
      "loss": 0.07,
      "step": 700
    },
    {
      "epoch": 1.88,
      "grad_norm": 0.2080078125,
      "learning_rate": 1.866666666666667e-05,
      "loss": 0.067,
      "step": 705
    },
    {
      "epoch": 1.89,
      "grad_norm": 0.2099609375,
      "learning_rate": 1.8444444444444445e-05,
      "loss": 0.0761,
      "step": 710
    },
    {
      "epoch": 1.91,
      "grad_norm": 0.265625,
      "learning_rate": 1.8222222222222224e-05,
      "loss": 0.0808,
      "step": 715
    },
    {
      "epoch": 1.92,
      "grad_norm": 0.248046875,
      "learning_rate": 1.8e-05,
      "loss": 0.076,
      "step": 720
    },
    {
      "epoch": 1.93,
      "grad_norm": 0.23828125,
      "learning_rate": 1.777777777777778e-05,
      "loss": 0.0744,
      "step": 725
    },
    {
      "epoch": 1.95,
      "grad_norm": 0.1767578125,
      "learning_rate": 1.7555555555555556e-05,
      "loss": 0.0682,
      "step": 730
    },
    {
      "epoch": 1.96,
      "grad_norm": 0.265625,
      "learning_rate": 1.7333333333333336e-05,
      "loss": 0.0705,
      "step": 735
    },
    {
      "epoch": 1.97,
      "grad_norm": 0.2197265625,
      "learning_rate": 1.7111111111111112e-05,
      "loss": 0.0723,
      "step": 740
    },
    {
      "epoch": 1.99,
      "grad_norm": 0.271484375,
      "learning_rate": 1.688888888888889e-05,
      "loss": 0.0818,
      "step": 745
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.189453125,
      "learning_rate": 1.6666666666666667e-05,
      "loss": 0.0806,
      "step": 750
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.2578125,
      "learning_rate": 1.6444444444444447e-05,
      "loss": 0.0678,
      "step": 755
    },
    {
      "epoch": 2.03,
      "grad_norm": 0.31640625,
      "learning_rate": 1.6222222222222223e-05,
      "loss": 0.0754,
      "step": 760
    },
    {
      "epoch": 2.04,
      "grad_norm": 0.255859375,
      "learning_rate": 1.6000000000000003e-05,
      "loss": 0.0726,
      "step": 765
    },
    {
      "epoch": 2.05,
      "grad_norm": 0.2294921875,
      "learning_rate": 1.577777777777778e-05,
      "loss": 0.0649,
      "step": 770
    },
    {
      "epoch": 2.07,
      "grad_norm": 0.205078125,
      "learning_rate": 1.5555555555555555e-05,
      "loss": 0.0749,
      "step": 775
    },
    {
      "epoch": 2.08,
      "grad_norm": 0.2333984375,
      "learning_rate": 1.5333333333333334e-05,
      "loss": 0.0728,
      "step": 780
    },
    {
      "epoch": 2.09,
      "grad_norm": 0.189453125,
      "learning_rate": 1.5111111111111112e-05,
      "loss": 0.0766,
      "step": 785
    },
    {
      "epoch": 2.11,
      "grad_norm": 0.25,
      "learning_rate": 1.4888888888888888e-05,
      "loss": 0.0768,
      "step": 790
    },
    {
      "epoch": 2.12,
      "grad_norm": 0.2314453125,
      "learning_rate": 1.4666666666666668e-05,
      "loss": 0.0705,
      "step": 795
    },
    {
      "epoch": 2.13,
      "grad_norm": 0.267578125,
      "learning_rate": 1.4444444444444444e-05,
      "loss": 0.0767,
      "step": 800
    },
    {
      "epoch": 2.15,
      "grad_norm": 0.2451171875,
      "learning_rate": 1.4222222222222224e-05,
      "loss": 0.0751,
      "step": 805
    },
    {
      "epoch": 2.16,
      "grad_norm": 0.26171875,
      "learning_rate": 1.4000000000000001e-05,
      "loss": 0.0773,
      "step": 810
    },
    {
      "epoch": 2.17,
      "grad_norm": 0.2197265625,
      "learning_rate": 1.3777777777777778e-05,
      "loss": 0.0818,
      "step": 815
    },
    {
      "epoch": 2.19,
      "grad_norm": 0.25,
      "learning_rate": 1.3555555555555557e-05,
      "loss": 0.0745,
      "step": 820
    },
    {
      "epoch": 2.2,
      "grad_norm": 0.265625,
      "learning_rate": 1.3333333333333333e-05,
      "loss": 0.0648,
      "step": 825
    },
    {
      "epoch": 2.21,
      "grad_norm": 0.189453125,
      "learning_rate": 1.3111111111111113e-05,
      "loss": 0.0682,
      "step": 830
    },
    {
      "epoch": 2.23,
      "grad_norm": 0.2099609375,
      "learning_rate": 1.2888888888888889e-05,
      "loss": 0.0705,
      "step": 835
    },
    {
      "epoch": 2.24,
      "grad_norm": 0.263671875,
      "learning_rate": 1.2666666666666668e-05,
      "loss": 0.0745,
      "step": 840
    },
    {
      "epoch": 2.25,
      "grad_norm": 0.291015625,
      "learning_rate": 1.2444444444444445e-05,
      "loss": 0.0736,
      "step": 845
    },
    {
      "epoch": 2.27,
      "grad_norm": 0.28515625,
      "learning_rate": 1.2222222222222222e-05,
      "loss": 0.084,
      "step": 850
    },
    {
      "epoch": 2.28,
      "grad_norm": 0.3046875,
      "learning_rate": 1.2e-05,
      "loss": 0.0722,
      "step": 855
    },
    {
      "epoch": 2.29,
      "grad_norm": 0.341796875,
      "learning_rate": 1.1777777777777778e-05,
      "loss": 0.0683,
      "step": 860
    },
    {
      "epoch": 2.31,
      "grad_norm": 0.2021484375,
      "learning_rate": 1.1555555555555556e-05,
      "loss": 0.0698,
      "step": 865
    },
    {
      "epoch": 2.32,
      "grad_norm": 0.2021484375,
      "learning_rate": 1.1333333333333334e-05,
      "loss": 0.0768,
      "step": 870
    },
    {
      "epoch": 2.33,
      "grad_norm": 0.2177734375,
      "learning_rate": 1.1111111111111112e-05,
      "loss": 0.0816,
      "step": 875
    },
    {
      "epoch": 2.35,
      "grad_norm": 0.2373046875,
      "learning_rate": 1.088888888888889e-05,
      "loss": 0.0739,
      "step": 880
    },
    {
      "epoch": 2.36,
      "grad_norm": 0.2490234375,
      "learning_rate": 1.0666666666666667e-05,
      "loss": 0.0784,
      "step": 885
    },
    {
      "epoch": 2.37,
      "grad_norm": 0.265625,
      "learning_rate": 1.0444444444444445e-05,
      "loss": 0.0792,
      "step": 890
    },
    {
      "epoch": 2.39,
      "grad_norm": 0.2236328125,
      "learning_rate": 1.0222222222222223e-05,
      "loss": 0.0717,
      "step": 895
    },
    {
      "epoch": 2.4,
      "grad_norm": 0.267578125,
      "learning_rate": 1e-05,
      "loss": 0.078,
      "step": 900
    },
    {
      "epoch": 2.41,
      "grad_norm": 0.306640625,
      "learning_rate": 9.777777777777779e-06,
      "loss": 0.0787,
      "step": 905
    },
    {
      "epoch": 2.43,
      "grad_norm": 0.3046875,
      "learning_rate": 9.555555555555556e-06,
      "loss": 0.0679,
      "step": 910
    },
    {
      "epoch": 2.44,
      "grad_norm": 0.24609375,
      "learning_rate": 9.333333333333334e-06,
      "loss": 0.0795,
      "step": 915
    },
    {
      "epoch": 2.45,
      "grad_norm": 0.333984375,
      "learning_rate": 9.111111111111112e-06,
      "loss": 0.076,
      "step": 920
    },
    {
      "epoch": 2.47,
      "grad_norm": 0.251953125,
      "learning_rate": 8.88888888888889e-06,
      "loss": 0.0756,
      "step": 925
    },
    {
      "epoch": 2.48,
      "grad_norm": 0.21875,
      "learning_rate": 8.666666666666668e-06,
      "loss": 0.0801,
      "step": 930
    },
    {
      "epoch": 2.49,
      "grad_norm": 0.212890625,
      "learning_rate": 8.444444444444446e-06,
      "loss": 0.0741,
      "step": 935
    },
    {
      "epoch": 2.51,
      "grad_norm": 0.341796875,
      "learning_rate": 8.222222222222223e-06,
      "loss": 0.0814,
      "step": 940
    },
    {
      "epoch": 2.52,
      "grad_norm": 0.21875,
      "learning_rate": 8.000000000000001e-06,
      "loss": 0.0769,
      "step": 945
    },
    {
      "epoch": 2.53,
      "grad_norm": 0.2470703125,
      "learning_rate": 7.777777777777777e-06,
      "loss": 0.0733,
      "step": 950
    },
    {
      "epoch": 2.55,
      "grad_norm": 0.2138671875,
      "learning_rate": 7.555555555555556e-06,
      "loss": 0.0728,
      "step": 955
    },
    {
      "epoch": 2.56,
      "grad_norm": 0.2001953125,
      "learning_rate": 7.333333333333334e-06,
      "loss": 0.0709,
      "step": 960
    },
    {
      "epoch": 2.57,
      "grad_norm": 0.244140625,
      "learning_rate": 7.111111111111112e-06,
      "loss": 0.0728,
      "step": 965
    },
    {
      "epoch": 2.59,
      "grad_norm": 0.359375,
      "learning_rate": 6.888888888888889e-06,
      "loss": 0.0808,
      "step": 970
    },
    {
      "epoch": 2.6,
      "grad_norm": 0.291015625,
      "learning_rate": 6.666666666666667e-06,
      "loss": 0.0764,
      "step": 975
    },
    {
      "epoch": 2.61,
      "grad_norm": 0.2275390625,
      "learning_rate": 6.4444444444444445e-06,
      "loss": 0.0786,
      "step": 980
    },
    {
      "epoch": 2.63,
      "grad_norm": 0.240234375,
      "learning_rate": 6.222222222222222e-06,
      "loss": 0.0655,
      "step": 985
    },
    {
      "epoch": 2.64,
      "grad_norm": 0.208984375,
      "learning_rate": 6e-06,
      "loss": 0.069,
      "step": 990
    },
    {
      "epoch": 2.65,
      "grad_norm": 0.259765625,
      "learning_rate": 5.777777777777778e-06,
      "loss": 0.0798,
      "step": 995
    },
    {
      "epoch": 2.67,
      "grad_norm": 0.3125,
      "learning_rate": 5.555555555555556e-06,
      "loss": 0.0694,
      "step": 1000
    }
  ],
  "logging_steps": 5,
  "max_steps": 1125,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "total_flos": 4.809547135414272e+16,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
