{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.3333333333333333,
  "eval_steps": 500,
  "global_step": 500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.01,
      "grad_norm": 2.46875,
      "learning_rate": 4.977777777777778e-05,
      "loss": 2.0633,
      "step": 5
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.3984375,
      "learning_rate": 4.955555555555556e-05,
      "loss": 1.6954,
      "step": 10
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.671875,
      "learning_rate": 4.933333333333334e-05,
      "loss": 1.4176,
      "step": 15
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.765625,
      "learning_rate": 4.9111111111111114e-05,
      "loss": 1.0952,
      "step": 20
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.6171875,
      "learning_rate": 4.888888888888889e-05,
      "loss": 0.761,
      "step": 25
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.3671875,
      "learning_rate": 4.866666666666667e-05,
      "loss": 0.4987,
      "step": 30
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.7421875,
      "learning_rate": 4.844444444444445e-05,
      "loss": 0.3189,
      "step": 35
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.74609375,
      "learning_rate": 4.8222222222222225e-05,
      "loss": 0.1894,
      "step": 40
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.62109375,
      "learning_rate": 4.8e-05,
      "loss": 0.1483,
      "step": 45
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.51953125,
      "learning_rate": 4.7777777777777784e-05,
      "loss": 0.1252,
      "step": 50
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.369140625,
      "learning_rate": 4.755555555555556e-05,
      "loss": 0.1137,
      "step": 55
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.70703125,
      "learning_rate": 4.7333333333333336e-05,
      "loss": 0.1066,
      "step": 60
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.59375,
      "learning_rate": 4.711111111111111e-05,
      "loss": 0.1135,
      "step": 65
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.59765625,
      "learning_rate": 4.6888888888888895e-05,
      "loss": 0.1072,
      "step": 70
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.4375,
      "learning_rate": 4.666666666666667e-05,
      "loss": 0.0999,
      "step": 75
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.50390625,
      "learning_rate": 4.644444444444445e-05,
      "loss": 0.1021,
      "step": 80
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.53515625,
      "learning_rate": 4.6222222222222224e-05,
      "loss": 0.0975,
      "step": 85
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.42578125,
      "learning_rate": 4.600000000000001e-05,
      "loss": 0.0941,
      "step": 90
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.50390625,
      "learning_rate": 4.577777777777778e-05,
      "loss": 0.0934,
      "step": 95
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.5390625,
      "learning_rate": 4.555555555555556e-05,
      "loss": 0.0907,
      "step": 100
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.384765625,
      "learning_rate": 4.5333333333333335e-05,
      "loss": 0.0791,
      "step": 105
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.50390625,
      "learning_rate": 4.511111111111112e-05,
      "loss": 0.0826,
      "step": 110
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.5546875,
      "learning_rate": 4.4888888888888894e-05,
      "loss": 0.0854,
      "step": 115
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.412109375,
      "learning_rate": 4.466666666666667e-05,
      "loss": 0.0913,
      "step": 120
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.34765625,
      "learning_rate": 4.4444444444444447e-05,
      "loss": 0.0834,
      "step": 125
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.3515625,
      "learning_rate": 4.422222222222222e-05,
      "loss": 0.0862,
      "step": 130
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.408203125,
      "learning_rate": 4.4000000000000006e-05,
      "loss": 0.0921,
      "step": 135
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.3203125,
      "learning_rate": 4.377777777777778e-05,
      "loss": 0.074,
      "step": 140
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.5703125,
      "learning_rate": 4.355555555555556e-05,
      "loss": 0.0831,
      "step": 145
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.345703125,
      "learning_rate": 4.3333333333333334e-05,
      "loss": 0.0815,
      "step": 150
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.31640625,
      "learning_rate": 4.311111111111111e-05,
      "loss": 0.0832,
      "step": 155
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.318359375,
      "learning_rate": 4.2888888888888886e-05,
      "loss": 0.0839,
      "step": 160
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.6640625,
      "learning_rate": 4.266666666666667e-05,
      "loss": 0.0949,
      "step": 165
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.330078125,
      "learning_rate": 4.2444444444444445e-05,
      "loss": 0.0881,
      "step": 170
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.34375,
      "learning_rate": 4.222222222222222e-05,
      "loss": 0.0873,
      "step": 175
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.36328125,
      "learning_rate": 4.2e-05,
      "loss": 0.0857,
      "step": 180
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.37109375,
      "learning_rate": 4.177777777777778e-05,
      "loss": 0.0859,
      "step": 185
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.37109375,
      "learning_rate": 4.155555555555556e-05,
      "loss": 0.0858,
      "step": 190
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.2890625,
      "learning_rate": 4.133333333333333e-05,
      "loss": 0.0762,
      "step": 195
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.357421875,
      "learning_rate": 4.111111111111111e-05,
      "loss": 0.0814,
      "step": 200
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.373046875,
      "learning_rate": 4.088888888888889e-05,
      "loss": 0.0854,
      "step": 205
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.33203125,
      "learning_rate": 4.066666666666667e-05,
      "loss": 0.0821,
      "step": 210
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.2578125,
      "learning_rate": 4.0444444444444444e-05,
      "loss": 0.0814,
      "step": 215
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.2021484375,
      "learning_rate": 4.022222222222222e-05,
      "loss": 0.0766,
      "step": 220
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.2236328125,
      "learning_rate": 4e-05,
      "loss": 0.0812,
      "step": 225
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.287109375,
      "learning_rate": 3.977777777777778e-05,
      "loss": 0.0755,
      "step": 230
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.37109375,
      "learning_rate": 3.9555555555555556e-05,
      "loss": 0.0822,
      "step": 235
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.30078125,
      "learning_rate": 3.933333333333333e-05,
      "loss": 0.0788,
      "step": 240
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.2333984375,
      "learning_rate": 3.9111111111111115e-05,
      "loss": 0.0814,
      "step": 245
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.294921875,
      "learning_rate": 3.888888888888889e-05,
      "loss": 0.0774,
      "step": 250
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.255859375,
      "learning_rate": 3.866666666666667e-05,
      "loss": 0.0787,
      "step": 255
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.2470703125,
      "learning_rate": 3.844444444444444e-05,
      "loss": 0.0837,
      "step": 260
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.271484375,
      "learning_rate": 3.8222222222222226e-05,
      "loss": 0.0737,
      "step": 265
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.2490234375,
      "learning_rate": 3.8e-05,
      "loss": 0.072,
      "step": 270
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.271484375,
      "learning_rate": 3.777777777777778e-05,
      "loss": 0.0852,
      "step": 275
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.291015625,
      "learning_rate": 3.7555555555555554e-05,
      "loss": 0.0788,
      "step": 280
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.248046875,
      "learning_rate": 3.733333333333334e-05,
      "loss": 0.0814,
      "step": 285
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.2353515625,
      "learning_rate": 3.7111111111111113e-05,
      "loss": 0.0752,
      "step": 290
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.2177734375,
      "learning_rate": 3.688888888888889e-05,
      "loss": 0.0752,
      "step": 295
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.294921875,
      "learning_rate": 3.6666666666666666e-05,
      "loss": 0.0774,
      "step": 300
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.23046875,
      "learning_rate": 3.644444444444445e-05,
      "loss": 0.0803,
      "step": 305
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.212890625,
      "learning_rate": 3.6222222222222225e-05,
      "loss": 0.081,
      "step": 310
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.2490234375,
      "learning_rate": 3.6e-05,
      "loss": 0.0787,
      "step": 315
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.1650390625,
      "learning_rate": 3.577777777777778e-05,
      "loss": 0.0888,
      "step": 320
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.1796875,
      "learning_rate": 3.555555555555556e-05,
      "loss": 0.0734,
      "step": 325
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.396484375,
      "learning_rate": 3.5333333333333336e-05,
      "loss": 0.081,
      "step": 330
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.267578125,
      "learning_rate": 3.511111111111111e-05,
      "loss": 0.0756,
      "step": 335
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.228515625,
      "learning_rate": 3.4888888888888895e-05,
      "loss": 0.0815,
      "step": 340
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.318359375,
      "learning_rate": 3.466666666666667e-05,
      "loss": 0.0756,
      "step": 345
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.2333984375,
      "learning_rate": 3.444444444444445e-05,
      "loss": 0.0808,
      "step": 350
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.328125,
      "learning_rate": 3.4222222222222224e-05,
      "loss": 0.0745,
      "step": 355
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.267578125,
      "learning_rate": 3.4000000000000007e-05,
      "loss": 0.073,
      "step": 360
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.294921875,
      "learning_rate": 3.377777777777778e-05,
      "loss": 0.0772,
      "step": 365
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.291015625,
      "learning_rate": 3.355555555555556e-05,
      "loss": 0.0825,
      "step": 370
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.28515625,
      "learning_rate": 3.3333333333333335e-05,
      "loss": 0.0797,
      "step": 375
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.212890625,
      "learning_rate": 3.311111111111112e-05,
      "loss": 0.0734,
      "step": 380
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.298828125,
      "learning_rate": 3.2888888888888894e-05,
      "loss": 0.0848,
      "step": 385
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.244140625,
      "learning_rate": 3.266666666666667e-05,
      "loss": 0.0782,
      "step": 390
    },
    {
      "epoch": 1.05,
      "grad_norm": 0.31640625,
      "learning_rate": 3.2444444444444446e-05,
      "loss": 0.0748,
      "step": 395
    },
    {
      "epoch": 1.07,
      "grad_norm": 0.234375,
      "learning_rate": 3.222222222222223e-05,
      "loss": 0.0791,
      "step": 400
    },
    {
      "epoch": 1.08,
      "grad_norm": 0.322265625,
      "learning_rate": 3.2000000000000005e-05,
      "loss": 0.0823,
      "step": 405
    },
    {
      "epoch": 1.09,
      "grad_norm": 0.26953125,
      "learning_rate": 3.177777777777778e-05,
      "loss": 0.0766,
      "step": 410
    },
    {
      "epoch": 1.11,
      "grad_norm": 0.205078125,
      "learning_rate": 3.155555555555556e-05,
      "loss": 0.0747,
      "step": 415
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.296875,
      "learning_rate": 3.1333333333333334e-05,
      "loss": 0.0729,
      "step": 420
    },
    {
      "epoch": 1.13,
      "grad_norm": 0.25390625,
      "learning_rate": 3.111111111111111e-05,
      "loss": 0.0822,
      "step": 425
    },
    {
      "epoch": 1.15,
      "grad_norm": 0.30859375,
      "learning_rate": 3.088888888888889e-05,
      "loss": 0.0787,
      "step": 430
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.2080078125,
      "learning_rate": 3.066666666666667e-05,
      "loss": 0.0807,
      "step": 435
    },
    {
      "epoch": 1.17,
      "grad_norm": 0.2392578125,
      "learning_rate": 3.044444444444445e-05,
      "loss": 0.0841,
      "step": 440
    },
    {
      "epoch": 1.19,
      "grad_norm": 0.2119140625,
      "learning_rate": 3.0222222222222225e-05,
      "loss": 0.0733,
      "step": 445
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.337890625,
      "learning_rate": 3e-05,
      "loss": 0.0833,
      "step": 450
    },
    {
      "epoch": 1.21,
      "grad_norm": 0.50390625,
      "learning_rate": 2.9777777777777777e-05,
      "loss": 0.0771,
      "step": 455
    },
    {
      "epoch": 1.23,
      "grad_norm": 0.2060546875,
      "learning_rate": 2.955555555555556e-05,
      "loss": 0.0801,
      "step": 460
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.2060546875,
      "learning_rate": 2.9333333333333336e-05,
      "loss": 0.0709,
      "step": 465
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.2041015625,
      "learning_rate": 2.9111111111111112e-05,
      "loss": 0.0745,
      "step": 470
    },
    {
      "epoch": 1.27,
      "grad_norm": 0.197265625,
      "learning_rate": 2.8888888888888888e-05,
      "loss": 0.079,
      "step": 475
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.2138671875,
      "learning_rate": 2.8666666666666668e-05,
      "loss": 0.0725,
      "step": 480
    },
    {
      "epoch": 1.29,
      "grad_norm": 0.224609375,
      "learning_rate": 2.8444444444444447e-05,
      "loss": 0.0728,
      "step": 485
    },
    {
      "epoch": 1.31,
      "grad_norm": 0.279296875,
      "learning_rate": 2.8222222222222223e-05,
      "loss": 0.0728,
      "step": 490
    },
    {
      "epoch": 1.32,
      "grad_norm": 0.279296875,
      "learning_rate": 2.8000000000000003e-05,
      "loss": 0.0803,
      "step": 495
    },
    {
      "epoch": 1.33,
      "grad_norm": 0.26953125,
      "learning_rate": 2.777777777777778e-05,
      "loss": 0.0805,
      "step": 500
    }
  ],
  "logging_steps": 5,
  "max_steps": 1125,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "total_flos": 2.4046819346325504e+16,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
