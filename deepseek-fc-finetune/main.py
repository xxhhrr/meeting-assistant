# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0. ç¯å¢ƒå¯¼å…¥ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
import json, torch
from datasets import load_dataset
from transformers import (
    AutoTokenizer, AutoModelForCausalLM, TrainingArguments
)
from peft import PeftModel, LoraConfig, get_peft_model
from trl import SFTTrainer

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1. æ•°æ®é›† â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
data_path = "data/meeting_synthetic_train_fixed.jsonl"          # â† ä½ çš„â€œTool-è°ƒç”¨æ ¼å¼â€æ•°æ®
raw_ds = load_dataset("json", data_files=data_path)["train"]

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 2. TokÂ­enizer â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
base_model_id = "deepseek-ai/deepseek-llm-7b-chat"
tok = AutoTokenizer.from_pretrained(base_model_id, trust_remote_code=True)
tok.pad_token = tok.eos_token          # å¿…ä¸å¯å°‘
tok.padding_side = "right"
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 3. æ ¼å¼åŒ–å‡½æ•° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def formatting_func(example):
    prompt = f"### Instruction:\n{example['instruction']}\n\n### Output:\n"
    output = json.dumps(example["output"], ensure_ascii=False)
    return [f"<|user|>\n{prompt}\n<|assistant|>\n{output}"]

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 4. æ¨¡å‹ï¼šåŠ è½½ä¸Šä¸€é˜¶æ®µ LoRA â”€
base = AutoModelForCausalLM.from_pretrained(
    base_model_id,
    device_map="auto",
    torch_dtype="auto",
    trust_remote_code=True
)
lora_cfg = LoraConfig(
    r=16,
    lora_alpha=32,
    lora_dropout=0.1,
    bias="none",
    task_type="CAUSAL_LM",
    target_modules=["q_proj", "k_proj", "v_proj", "o_proj"],
)
model = get_peft_model(base,lora_cfg)  # â† å·²æœ‰ LoRA
model.enable_input_require_grads()
model.gradient_checkpointing_enable()
model.config.use_cache = False

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 5. è®­ç»ƒå‚æ•° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
train_args = TrainingArguments(
    output_dir="output/deepseek-lora-stage2",
    per_device_train_batch_size=1,
    gradient_accumulation_steps=8,
    num_train_epochs=3,
    learning_rate=5e-5,
    fp16=False,
    bf16=False,
    logging_steps=5,
    remove_unused_columns=False,
    max_grad_norm=0.3,
)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 6. SFTTrainer â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
trainer = SFTTrainer(
    model=model,
    args=train_args,
    train_dataset=raw_ds,          # æœª token åŒ–åŸå§‹æ•°æ®
    tokenizer=tok,                 # â† è¿™é‡Œéœ€è¦ tok
    formatting_func=formatting_func,
    max_seq_length=512,
    dataset_batch_size=1,
)

# # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 7. è®­ç»ƒ & ä¿å­˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# n_trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)
# n_total = sum(p.numel() for p in model.parameters())
# print(f"ğŸ” å¯è®­ç»ƒå‚æ•°æ•°é‡: {n_trainable:,} / {n_total:,} ({n_trainable / n_total:.4%})")
trainer.train()
trainer.save_model("output/deepseek-lora-stage2")  # äºŒé˜¶æ®µ LoRA